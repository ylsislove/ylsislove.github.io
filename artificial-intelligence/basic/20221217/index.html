<!-- build time:Mon Oct 02 2023 23:53:48 GMT+0800 (China Standard Time) --><!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#FFF"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png"><link rel="icon" type="image/ico" sizes="32x32" href="/images/favicon.ico"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="alternate" type="application/rss+xml" title="学无止境" href="https://blog.aayu.today/rss.xml"><link rel="alternate" type="application/atom+xml" title="学无止境" href="https://blog.aayu.today/atom.xml"><link rel="alternate" type="application/json" title="学无止境" href="https://blog.aayu.today/feed.json"><link rel="stylesheet" href="/assets/fonts.googleapis.com.css"><link rel="stylesheet" href="/css/app.css?v=0.2.5"><meta name="keywords" content="win11,wsl,nvidia"><link rel="canonical" href="https://blog.aayu.today/artificial-intelligence/basic/20221217/"><title>Win11安装WSL2和Nvidia驱动 - 基础知识 - 人工智能 | Aayu Yain = 学无止境 = 世界上大部分事，都没太大意义。真理与热爱除外</title><meta name="generator" content="Hexo 5.4.0"></head><body itemscope itemtype="http://schema.org/WebPage"><div id="loading"><div class="cat"><div class="body"></div><div class="head"><div class="face"></div></div><div class="foot"><div class="tummy-end"></div><div class="bottom"></div><div class="legs left"></div><div class="legs right"></div></div><div class="paw"><div class="hands left"></div><div class="hands right"></div></div></div></div><div id="container"><header id="header" itemscope itemtype="http://schema.org/WPHeader"><div class="inner"><div id="brand"><div class="pjax"><h1 itemprop="name headline">Win11安装WSL2和Nvidia驱动</h1><div class="meta"><span class="item" title="创建时间：2022-12-17 21:09:51"><span class="icon"><i class="ic i-calendar"></i> </span><span class="text">发表于</span> <time itemprop="dateCreated datePublished" datetime="2022-12-17T21:09:51+08:00">2022-12-17</time> </span><span class="item" title="本文字数"><span class="icon"><i class="ic i-pen"></i> </span><span class="text">本文字数</span> <span>11k</span> <span class="text">字</span> </span><span class="item" title="阅读时长"><span class="icon"><i class="ic i-clock"></i> </span><span class="text">阅读时长</span> <span>10 分钟</span></span></div></div></div><nav id="nav"><div class="inner"><div class="toggle"><div class="lines" aria-label="切换导航栏"><span class="line"></span> <span class="line"></span> <span class="line"></span></div></div><ul class="menu"><li class="item title"><a href="/" rel="start">Aayu Yain</a></li></ul><ul class="right"><li class="item theme"><i class="ic i-sun"></i></li><li class="item search"><i class="ic i-search"></i></li></ul></div></nav></div><div id="imgs" class="pjax"><ul><li class="item" data-background-image="https://image.aayu.today/uploads/2023/08/14/202308142341005.png"></li><li class="item" data-background-image="https://image.aayu.today/uploads/2022/08/22/eb3c02960b932.jpg"></li><li class="item" data-background-image="https://image.aayu.today/uploads/2023/09/04/202309042336361.png"></li><li class="item" data-background-image="https://image.aayu.today/uploads/2022/12/28/6833939bly1giciukx8a7j20zk0m8aio.jpg"></li><li class="item" data-background-image="https://image.aayu.today/uploads/2022/12/28/6833939bly1giclize41wj20zk0m87gk.jpg"></li><li class="item" data-background-image="https://image.aayu.today/uploads/2022/12/28/6833939bly1giph4baakhj20zk0m8h5q.jpg"></li></ul></div></header><div id="waves"><svg class="waves" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 24 150 28" preserveAspectRatio="none" shape-rendering="auto"><defs><path id="gentle-wave" d="M-160 44c30 0 58-18 88-18s 58 18 88 18 58-18 88-18 58 18 88 18 v44h-352z"/></defs><g class="parallax"><use xlink:href="#gentle-wave" x="48" y="0"/><use xlink:href="#gentle-wave" x="48" y="3"/><use xlink:href="#gentle-wave" x="48" y="5"/><use xlink:href="#gentle-wave" x="48" y="7"/></g></svg></div><main><div class="inner"><div id="main" class="pjax"><div class="article wrap"><div class="breadcrumb" itemscope itemtype="https://schema.org/BreadcrumbList"><i class="ic i-home"></i> <span><a href="/">首页</a></span><i class="ic i-angle-right"></i> <span itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a href="/categories/artificial-intelligence/" itemprop="item" rel="index" title="分类于 人工智能"><span itemprop="name">人工智能</span></a><meta itemprop="position" content="1"></span><i class="ic i-angle-right"></i> <span class="current" itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a href="/categories/artificial-intelligence/basic/" itemprop="item" rel="index" title="分类于 基础知识"><span itemprop="name">基础知识</span></a><meta itemprop="position" content="2"></span></div><article itemscope itemtype="http://schema.org/Article" class="post block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://blog.aayu.today/artificial-intelligence/basic/20221217/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.jpg"><meta itemprop="name" content="宇凌喵"><meta itemprop="description" content="世界上大部分事，都没太大意义。真理与热爱除外, 真理和热爱是吾永生的追求"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="学无止境"></span><div class="body md" itemprop="articleBody"><h2 id="前言"><a class="anchor" href="#前言">#</a> 前言</h2><p>以前捣鼓过 wsl，即 Windows 下的 Linux 子系统，但兼容性依然比不过原生的 Linux 系统，使用 cmake 等命令会出现奇怪的问题。</p><p>最近听说 wsl2 出来了，而且也可以在 wsl 上安装 nvidia 显卡驱动了，有网友实测跑深度学习模型速度能比 Windows 的快一倍左右，哈哈这就必须得捣鼓捣鼓了，如果兼容性真的没问题的话，那可比虚拟机或双系统要爽多了～</p><p>目前还发现，微软官网对 wsl 的使用教程也写的非常友好，推荐大家多看看官方教程，毕竟时效性可以保证～～</p><p>微软 wsl 官方教程：<span class="exturl" data-url="aHR0cHM6Ly9sZWFybi5taWNyb3NvZnQuY29tL3poLWNuL3dpbmRvd3Mvd3NsL2luc3RhbGw=">https://learn.microsoft.com/zh-cn/windows/wsl/install</span></p><div class="note info"><p>wsl 安装过程中可能需要科学上网，推荐大家去「 <span class="exturl" data-url="aHR0cHM6Ly94bi0tNGdxNjJmNTJnZHNzLmNvbS8jL3JlZ2lzdGVyP2NvZGU9RHlkSkJ1dlc=">一元机场</span> 」平台订阅，每月 500G 流量月均 0.9 元，性价比拉满～</p></div><h2 id="系统环境"><a class="anchor" href="#系统环境">#</a> 系统环境</h2><ul><li>CPU：i5-12450</li><li>内存：32G</li><li>显卡：3060</li><li>Windows 版本：Windows11 22H2 22621.963</li></ul><div class="note warning"><p>本篇教程后面涉及到 WSL2 上的 GPU 加速，经网上帖子的建议，用最新的 win11 系统可以保证最大的成功率。如果是 win10 系统，需将 win10 升级为预览体验版本，建议谨慎折腾！</p><p>没特殊需求的，都建议将系统升级为 win11 再进行尝试。</p></div><h2 id="wsl-1和wsl-2功能对比"><a class="anchor" href="#wsl-1和wsl-2功能对比">#</a> WSL 1 和 WSL 2 功能对比</h2><p><img data-src="https://image.aayu.today/uploads/2022/12/17/202212172118749.png" alt="" width="800px"></p><p>从对比图中可以看到，除非对跨 OS 的文件系统性能有要求，WSL 2 是全面优于 WSL 1 的。官方文档也建议使用 VSCode 对 WSL 中的文件进行访问和操作，所以 WSL 2 搭配 VSCode 应该是非常棒的组合～</p><p><img data-src="https://image.aayu.today/uploads/2022/12/17/202212172122761.png" alt="" width="800px"></p><h2 id="安装wsl2"><a class="anchor" href="#安装wsl2">#</a> 安装 WSL2</h2><div class="note info"><p>管理员模式下打开 PowerShell 或 Windows 命令提示符</p></div><p>查看可用发行版本列表</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre>wsl --list --online</pre></td></tr></table></figure><p>可以看到有 <code>Ubuntu-20.04</code> 这个发行版本，正是我们需要的～</p><p>安装 <code>Ubuntu-20.04</code> 发行版</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre>wsl --install -d Ubuntu-20.04</pre></td></tr></table></figure><p>这里默认安装的就是 wsl2，如果对 wsl1 有需求，可以查阅官方文档哦，有很详尽的介绍～</p><p>安装大概花费 5~10 分钟左右，视电脑配置和网络状况，耐心等待即可～</p><p>提示安装成功后，重启电脑即可完成安装。重启后会默认弹出 Linux powershell，设置完用户名和密码，安装正式完成，如下图～</p><p><img data-src="https://image.aayu.today/uploads/2022/12/17/202212172134452.png" alt="" width="800px"></p><h2 id="更新和升级包"><a class="anchor" href="#更新和升级包">#</a> 更新和升级包</h2><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token function">sudo</span> <span class="token function">apt</span> update <span class="token operator">&amp;&amp;</span> <span class="token function">sudo</span> <span class="token function">apt</span> upgrade</pre></td></tr></table></figure><h2 id="配置vscode"><a class="anchor" href="#配置vscode">#</a> 配置 VSCode</h2><p>在 VSCode 中安装「 Remote Development 」扩展。除了远程 - SSH 和开发容器扩展，此扩展包还包括 WSL 扩展，使你能够在容器、远程计算机上或 WSL 中打开任何文件夹。</p><p>可以通过在 WSL2 命令行中输入 <code>code .</code> 就可以直接用 VSCode 打开 Linux 中的文件夹进行开发了～</p><h2 id="配置miniconda"><a class="anchor" href="#配置miniconda">#</a> 配置 MiniConda</h2><h3 id="安装miniconda"><a class="anchor" href="#安装miniconda">#</a> 安装 MiniConda</h3><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token function">wget</span> https://repo.anaconda.com/miniconda/Miniconda3-py39_4.12.0-Linux-x86_64.sh</pre></td></tr></table></figure><p>运行安装脚本</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token function">bash</span> Miniconda3-py39_4.12.0-Linux-x86_64.sh</pre></td></tr></table></figure><p>一直按回车，直到浏览完用户协议后输入 <code>yes</code> 。再次按回车使用默认安装位置，然后再次输入 <code>yes</code> 选择初始化 miniconda，初始化完成即安装成功</p><p>可以使用如下命令取消默认激活 base 环境</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre>conda config --set auto_activate_base <span class="token boolean">false</span></pre></td></tr></table></figure><p>安装完成后记得关闭 Linux 终端，打开 powershell 输入 <code>wsl</code> 可以重新进入 Linux 终端，使 conda 环境刷新</p><h3 id="配置miniconda-2"><a class="anchor" href="#配置miniconda-2">#</a> 配置 MiniConda</h3><p>创建用户配置文件</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre>conda config --set show_channel_urls <span class="token function">yes</span></pre></td></tr></table></figure><p>进入<span class="exturl" data-url="aHR0cHM6Ly9taXJyb3JzLnR1bmEudHNpbmdodWEuZWR1LmNuL2hlbHAvYW5hY29uZGEv">清华大学开源软件镜像站</span>，复制配置内容到用户目录下刚创建的 .condarc 文件，要复制的配置内容如下</p><figure class="highlight yaml"><figcaption data-lang="YAML"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token key atrule">channels</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="2"></td><td><pre>  <span class="token punctuation">-</span> defaults</pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token key atrule">show_channel_urls</span><span class="token punctuation">:</span> <span class="token boolean important">true</span></pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token key atrule">default_channels</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="5"></td><td><pre>  <span class="token punctuation">-</span> https<span class="token punctuation">:</span>//mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main</pre></td></tr><tr><td data-num="6"></td><td><pre>  <span class="token punctuation">-</span> https<span class="token punctuation">:</span>//mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/r</pre></td></tr><tr><td data-num="7"></td><td><pre>  <span class="token punctuation">-</span> https<span class="token punctuation">:</span>//mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/msys2</pre></td></tr><tr><td data-num="8"></td><td><pre><span class="token key atrule">custom_channels</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="9"></td><td><pre>  <span class="token key atrule">conda-forge</span><span class="token punctuation">:</span> https<span class="token punctuation">:</span>//mirrors.tuna.tsinghua.edu.cn/anaconda/cloud</pre></td></tr><tr><td data-num="10"></td><td><pre>  <span class="token key atrule">msys2</span><span class="token punctuation">:</span> https<span class="token punctuation">:</span>//mirrors.tuna.tsinghua.edu.cn/anaconda/cloud</pre></td></tr><tr><td data-num="11"></td><td><pre>  <span class="token key atrule">bioconda</span><span class="token punctuation">:</span> https<span class="token punctuation">:</span>//mirrors.tuna.tsinghua.edu.cn/anaconda/cloud</pre></td></tr><tr><td data-num="12"></td><td><pre>  <span class="token key atrule">menpo</span><span class="token punctuation">:</span> https<span class="token punctuation">:</span>//mirrors.tuna.tsinghua.edu.cn/anaconda/cloud</pre></td></tr><tr><td data-num="13"></td><td><pre>  <span class="token key atrule">pytorch</span><span class="token punctuation">:</span> https<span class="token punctuation">:</span>//mirrors.tuna.tsinghua.edu.cn/anaconda/cloud</pre></td></tr><tr><td data-num="14"></td><td><pre>  <span class="token key atrule">pytorch-lts</span><span class="token punctuation">:</span> https<span class="token punctuation">:</span>//mirrors.tuna.tsinghua.edu.cn/anaconda/cloud</pre></td></tr><tr><td data-num="15"></td><td><pre>  <span class="token key atrule">simpleitk</span><span class="token punctuation">:</span> https<span class="token punctuation">:</span>//mirrors.tuna.tsinghua.edu.cn/anaconda/cloud</pre></td></tr></table></figure><div class="note info"><p>注意，把 <code>.condarc</code> 文件默认的内容删掉</p></div><p>输入 <code>conda clean -i</code> 清除默认缓存，用 <code>conda config --show-sources</code> 查看配置是否更换成功</p><h2 id="pip换国内源linux环境"><a class="anchor" href="#pip换国内源linux环境">#</a> pip 换国内源（Linux 环境）</h2><h3 id="临时换源不推荐"><a class="anchor" href="#临时换源不推荐">#</a> 临时换源（不推荐）</h3><p>可能要安装包里的依赖包下载依然缓慢</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre>pip <span class="token function">install</span> -i https://pypi.tuna.tsinghua.edu.cn/simple 包名</pre></td></tr></table></figure><h3 id="永久换源推荐"><a class="anchor" href="#永久换源推荐">#</a> 永久换源（推荐）</h3><ol><li>在用户目录下创建.pip 文件夹</li><li>在刚创建的 pip 文件夹下创建 <code>pip.conf</code> 文件</li><li>把以下配置内容放到刚创建的 pip.conf 文件里</li></ol><figure class="highlight ini"><figcaption data-lang="ini"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token header"><span class="token punctuation">[</span><span class="token section-name selector">global</span><span class="token punctuation">]</span></span></pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token key attr-name">index-url</span> <span class="token punctuation">=</span> <span class="token value attr-value">https://pypi.tuna.tsinghua.edu.cn/simple/</span></pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token header"><span class="token punctuation">[</span><span class="token section-name selector">install</span><span class="token punctuation">]</span></span></pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token key attr-name">trusted-host</span> <span class="token punctuation">=</span> <span class="token value attr-value">pypi.tuna.tsinghua.edu.cn</span></pre></td></tr></table></figure><h2 id="配置gpu加速"><a class="anchor" href="#配置gpu加速">#</a> 配置 GPU 加速</h2><h3 id="安装nvidia驱动"><a class="anchor" href="#安装nvidia驱动">#</a> 安装 Nvidia 驱动</h3><p>下载并安装 NVIDIA GPU 的最新驱动程序：<span class="exturl" data-url="aHR0cHM6Ly93d3cubnZpZGlhLmNvbS9Eb3dubG9hZC9pbmRleC5hc3B4">https://www.nvidia.com/Download/index.aspx</span></p><p>我的笔记本是 3060，所以可以按如下配置搜索</p><p>搜索出来后点击下载即可，可以看到驱动版本目前最新是 527.56</p><p class="gallery" data-height="240"><img data-src="https://image.aayu.today/uploads/2022/12/18/202212180051600.png" alt=""><br><img data-src="https://image.aayu.today/uploads/2022/12/18/202212180059301.png" alt=""></p><div class="note warning"><p>这是您需要安装的唯一驱动程序。不要在 WSL 中安装任何 Linux 显卡驱动程序。<br>详情参阅 Nvidia 官方说明：<span class="exturl" data-url="aHR0cHM6Ly9kb2NzLm52aWRpYS5jbi9jdWRhL3dzbC11c2VyLWd1aWRlL2luZGV4Lmh0bWwjZ2V0dGluZy1zdGFydGVkLXdpdGgtY3VkYS1vbi13c2wtMg==">WSL 2 上的 CUDA 入门</span></p><p>再次强调，不要在 WSL 中安装任何 Linux 版的 Nvidia 驱动！</p></div><p>下载完驱动后就可以安装了，我直接选择默认的 <code>NVIDIA 显卡驱动和 GeForce Experience</code> 选项，安装选项为 <code>精简</code> ，安装完成后重启下电脑即可～</p><p>打开 powershell，输入 <code>nvidia-smi</code> ，可以看到 Windows 下已经正常输出显卡驱动信息了</p><p>输入 <code>wsl</code> ，可以进入 Linux 命令行，再次输入 <code>nvidia-smi</code> ，可以看到 Linux 环境下，也输出了显卡驱动信息，大功告成～</p><p class="gallery" data-height="280"><img data-src="https://image.aayu.today/uploads/2022/12/18/202212181857151.png" alt=""><br><img data-src="https://image.aayu.today/uploads/2022/12/18/202212181857604.png" alt=""></p><div class="note info"><p>如果在 wsl2 命令行中输入 <code>nvidia-smi</code> 发现没有正常输出，而是报错，首先要检查的就是你的 Windows 版本是不是太低了，还是建议升级到最新的 win11 系统再进行折腾</p><p>因为有<span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2l3YW52YW4vYXJ0aWNsZS9kZXRhaWxzLzEyMjExOTU5NQ==">网友已经实践</span>，升级到 win11 后啥都不用做，直接就把 wsl2 链接到 GPU 了</p><p>所以看到报错先检查 Windows 版本，千万不要在 WSL 中安装任何 Linux 版的 Nvidia 驱动！不需要的！</p></div><h3 id="安装cuda-toolkit"><a class="anchor" href="#安装cuda-toolkit">#</a> 安装 Cuda Toolkit</h3><p>接下来就有两种方式了：</p><p>一个是按 Nvidia 官方说明：<span class="exturl" data-url="aHR0cHM6Ly9kb2NzLm52aWRpYS5jbi9jdWRhL3dzbC11c2VyLWd1aWRlL2luZGV4Lmh0bWwjZ2V0dGluZy1zdGFydGVkLXdpdGgtY3VkYS1vbi13c2wtMg==">WSL 2 上的 CUDA 入门</span>上的，在<span class="exturl" data-url="aHR0cHM6Ly9kZXZlbG9wZXIubnZpZGlhLmNvbS9jdWRhLWRvd25sb2Fkcz90YXJnZXRfb3M9TGludXgmYW1wO3RhcmdldF9hcmNoPXg4Nl82NCZhbXA7RGlzdHJpYnV0aW9uPVdTTC1VYnVudHUmYW1wO3RhcmdldF92ZXJzaW9uPTIuMCZhbXA7dGFyZ2V0X3R5cGU9ZGViX25ldHdvcms="> CUDA Toolkit</span> 下载界面选择适合 WSL 的 CUDA Toolkit 进行安装，如下图所示</p><p><img data-src="https://image.aayu.today/uploads/2022/12/18/202212182152370.png" alt="" width="800px"></p><p>另一种是根据网友的评论，可以依赖于 conda 和 pytorch 直接安装 gpu 版本的 pytorch，安装成功后 cuda 也是可以直接用了。pytorch 官方给出的安装命令如下图，可以看到其中也包含了 cuda 11.7</p><p class="gallery" data-height="280"><img data-src="https://image.aayu.today/uploads/2022/12/19/202212191544772.png" alt=""><br><img data-src="https://image.aayu.today/uploads/2022/12/18/202212182203319.png" alt=""></p><div class="note warning"><p>这两种的区别，据有网友说第二种方式安装的 CUDA Toolkit 貌似只适用于 Pytorch，所以如果想将 CUDA Toolkit 和 C++ 搭配使用的话，还是得要用第一种方式安装一次 CUDA Toolkit</p><p>但经博主亲自实践，用 conda 安装的 cuda，也是可以直接和 C++ 搭配使用的！</p></div><p>所以接下来的内容就是，用第二种方式安装 pytorch 的 gpu 版本，即可将 cuda 安装好。然后编写一个 c++ 脚本测试一下，都没问题的话，即 WSL2 的 GPU 加速配置大功告成～</p><div class="note info"><p>本节教程和<span class="exturl" data-url="aHR0cHM6Ly9sZWFybi5taWNyb3NvZnQuY29tL3poLWNuL3dpbmRvd3Mvd3NsL2luc3RhbGw=">微软 wsl 官方教程</span>中的 GPU 加速配置有区别，好像是官方教程里好像设置了 Docker 什么的，我目前好像还用不到这么深，所以就没参考微软 wsl 的官方教程</p></div><h4 id="通过pytorch安装cuda-toolkit"><a class="anchor" href="#通过pytorch安装cuda-toolkit">#</a> 通过 PyTorch 安装 CUDA Toolkit</h4><p>首先我们先创建一个 python3.8 的虚拟环境，后续安装相关库都在这个环境下安装。保持环境一直可以减少很多 Bug 的产生</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre>conda create --name py38 <span class="token assign-left variable">python</span><span class="token operator">=</span><span class="token number">3.8</span></pre></td></tr></table></figure><p>激活新创建好的环境</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre>conda activate py38</pre></td></tr></table></figure><p>PyTorch 官网直接给出了安装命令，如下</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre>conda <span class="token function">install</span> pytorch torchvision torchaudio pytorch-cuda<span class="token operator">=</span><span class="token number">11.7</span> -c pytorch -c nvidia</pre></td></tr></table></figure><p>因此，我们直接在 Linux 的命令行中，切换到我们自己创建的 python 虚拟环境，运行以上命令进行安装，以下是 conda 给出安装前的输出信息，可以看到里面就包含了 CUDA Toolkit</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token comment">## Package Plan ##</span></pre></td></tr><tr><td data-num="2"></td><td><pre></pre></td></tr><tr><td data-num="3"></td><td><pre>  environment location: /home/aayu/miniconda3/envs/py38</pre></td></tr><tr><td data-num="4"></td><td><pre></pre></td></tr><tr><td data-num="5"></td><td><pre>  added / updated specs:</pre></td></tr><tr><td data-num="6"></td><td><pre>    - pytorch</pre></td></tr><tr><td data-num="7"></td><td><pre>    - pytorch-cuda<span class="token operator">=</span><span class="token number">11.7</span></pre></td></tr><tr><td data-num="8"></td><td><pre>    - torchaudio</pre></td></tr><tr><td data-num="9"></td><td><pre>    - torchvision</pre></td></tr><tr><td data-num="10"></td><td><pre></pre></td></tr><tr><td data-num="11"></td><td><pre></pre></td></tr><tr><td data-num="12"></td><td><pre>The following packages will be downloaded:</pre></td></tr><tr><td data-num="13"></td><td><pre></pre></td></tr><tr><td data-num="14"></td><td><pre>    package                    <span class="token operator">|</span>            build</pre></td></tr><tr><td data-num="15"></td><td><pre>    ---------------------------<span class="token operator">|</span>-----------------</pre></td></tr><tr><td data-num="16"></td><td><pre>    cuda-11.7.1                <span class="token operator">|</span>                <span class="token number">0</span>           <span class="token number">1</span> KB  nvidia</pre></td></tr><tr><td data-num="17"></td><td><pre>    cuda-cccl-11.7.91          <span class="token operator">|</span>                <span class="token number">0</span>         <span class="token number">1.2</span> MB  nvidia</pre></td></tr><tr><td data-num="18"></td><td><pre>    cuda-command-line-tools-11.7.1<span class="token operator">|</span>                <span class="token number">0</span>           <span class="token number">1</span> KB  nvidia</pre></td></tr><tr><td data-num="19"></td><td><pre>    cuda-compiler-11.7.1       <span class="token operator">|</span>                <span class="token number">0</span>           <span class="token number">1</span> KB  nvidia</pre></td></tr><tr><td data-num="20"></td><td><pre>    cuda-cudart-11.7.99        <span class="token operator">|</span>                <span class="token number">0</span>         <span class="token number">194</span> KB  nvidia</pre></td></tr><tr><td data-num="21"></td><td><pre>    cuda-cudart-dev-11.7.99    <span class="token operator">|</span>                <span class="token number">0</span>         <span class="token number">1.1</span> MB  nvidia</pre></td></tr><tr><td data-num="22"></td><td><pre>    cuda-cuobjdump-11.7.91     <span class="token operator">|</span>                <span class="token number">0</span>         <span class="token number">158</span> KB  nvidia</pre></td></tr><tr><td data-num="23"></td><td><pre>    cuda-cupti-11.7.101        <span class="token operator">|</span>                <span class="token number">0</span>        <span class="token number">22.9</span> MB  nvidia</pre></td></tr><tr><td data-num="24"></td><td><pre>    cuda-cuxxfilt-11.7.91      <span class="token operator">|</span>                <span class="token number">0</span>         <span class="token number">293</span> KB  nvidia</pre></td></tr><tr><td data-num="25"></td><td><pre>    cuda-demo-suite-12.0.76    <span class="token operator">|</span>                <span class="token number">0</span>         <span class="token number">5.0</span> MB  nvidia</pre></td></tr><tr><td data-num="26"></td><td><pre>    cuda-documentation-12.0.76 <span class="token operator">|</span>                <span class="token number">0</span>          <span class="token number">89</span> KB  nvidia</pre></td></tr><tr><td data-num="27"></td><td><pre>    cuda-driver-dev-11.7.99    <span class="token operator">|</span>                <span class="token number">0</span>          <span class="token number">16</span> KB  nvidia</pre></td></tr><tr><td data-num="28"></td><td><pre>    cuda-gdb-12.0.90           <span class="token operator">|</span>                <span class="token number">0</span>         <span class="token number">5.3</span> MB  nvidia</pre></td></tr><tr><td data-num="29"></td><td><pre>    cuda-libraries-11.7.1      <span class="token operator">|</span>                <span class="token number">0</span>           <span class="token number">1</span> KB  nvidia</pre></td></tr><tr><td data-num="30"></td><td><pre>    cuda-libraries-dev-11.7.1  <span class="token operator">|</span>                <span class="token number">0</span>           <span class="token number">2</span> KB  nvidia</pre></td></tr><tr><td data-num="31"></td><td><pre>    cuda-memcheck-11.8.86      <span class="token operator">|</span>                <span class="token number">0</span>         <span class="token number">168</span> KB  nvidia</pre></td></tr><tr><td data-num="32"></td><td><pre>    cuda-nsight-12.0.78        <span class="token operator">|</span>                <span class="token number">0</span>       <span class="token number">113.6</span> MB  nvidia</pre></td></tr><tr><td data-num="33"></td><td><pre>    cuda-nsight-compute-12.0.0 <span class="token operator">|</span>                <span class="token number">0</span>           <span class="token number">1</span> KB  nvidia</pre></td></tr><tr><td data-num="34"></td><td><pre>    cuda-nvcc-11.7.99          <span class="token operator">|</span>                <span class="token number">0</span>        <span class="token number">42.7</span> MB  nvidia</pre></td></tr><tr><td data-num="35"></td><td><pre>    cuda-nvdisasm-12.0.76      <span class="token operator">|</span>                <span class="token number">0</span>        <span class="token number">47.9</span> MB  nvidia</pre></td></tr><tr><td data-num="36"></td><td><pre>    cuda-nvml-dev-11.7.91      <span class="token operator">|</span>                <span class="token number">0</span>          <span class="token number">80</span> KB  nvidia</pre></td></tr><tr><td data-num="37"></td><td><pre>    cuda-nvprof-12.0.90        <span class="token operator">|</span>                <span class="token number">0</span>         <span class="token number">4.3</span> MB  nvidia</pre></td></tr><tr><td data-num="38"></td><td><pre>    cuda-nvprune-11.7.91       <span class="token operator">|</span>                <span class="token number">0</span>          <span class="token number">64</span> KB  nvidia</pre></td></tr><tr><td data-num="39"></td><td><pre>    cuda-nvrtc-11.7.99         <span class="token operator">|</span>                <span class="token number">0</span>        <span class="token number">17.3</span> MB  nvidia</pre></td></tr><tr><td data-num="40"></td><td><pre>    cuda-nvrtc-dev-11.7.99     <span class="token operator">|</span>                <span class="token number">0</span>        <span class="token number">16.9</span> MB  nvidia</pre></td></tr><tr><td data-num="41"></td><td><pre>    cuda-nvtx-11.7.91          <span class="token operator">|</span>                <span class="token number">0</span>          <span class="token number">57</span> KB  nvidia</pre></td></tr><tr><td data-num="42"></td><td><pre>    cuda-nvvp-12.0.90          <span class="token operator">|</span>                <span class="token number">0</span>       <span class="token number">114.3</span> MB  nvidia</pre></td></tr><tr><td data-num="43"></td><td><pre>    cuda-runtime-11.7.1        <span class="token operator">|</span>                <span class="token number">0</span>           <span class="token number">1</span> KB  nvidia</pre></td></tr><tr><td data-num="44"></td><td><pre>    cuda-sanitizer-api-12.0.90 <span class="token operator">|</span>                <span class="token number">0</span>        <span class="token number">16.6</span> MB  nvidia</pre></td></tr><tr><td data-num="45"></td><td><pre>    cuda-toolkit-11.7.1        <span class="token operator">|</span>                <span class="token number">0</span>           <span class="token number">1</span> KB  nvidia</pre></td></tr><tr><td data-num="46"></td><td><pre>    cuda-tools-11.7.1          <span class="token operator">|</span>                <span class="token number">0</span>           <span class="token number">1</span> KB  nvidia</pre></td></tr><tr><td data-num="47"></td><td><pre>    cuda-visual-tools-11.7.1   <span class="token operator">|</span>                <span class="token number">0</span>           <span class="token number">1</span> KB  nvidia</pre></td></tr><tr><td data-num="48"></td><td><pre>    cudatoolkit-10.1.243       <span class="token operator">|</span>       h036e899_8       <span class="token number">427.4</span> MB  nvidia</pre></td></tr><tr><td data-num="49"></td><td><pre>    gds-tools-1.5.0.59         <span class="token operator">|</span>                <span class="token number">0</span>        <span class="token number">40.9</span> MB  nvidia</pre></td></tr><tr><td data-num="50"></td><td><pre>    intel-openmp-2022.1.0      <span class="token operator">|</span>    h9e868ea_3769         <span class="token number">4.5</span> MB</pre></td></tr><tr><td data-num="51"></td><td><pre>    lcms2-2.12                 <span class="token operator">|</span>       h3be6417_0         <span class="token number">312</span> KB</pre></td></tr><tr><td data-num="52"></td><td><pre>    libcublas-11.10.3.66       <span class="token operator">|</span>                <span class="token number">0</span>       <span class="token number">286.1</span> MB  nvidia</pre></td></tr><tr><td data-num="53"></td><td><pre>    libcublas-dev-11.10.3.66   <span class="token operator">|</span>                <span class="token number">0</span>       <span class="token number">296.4</span> MB  nvidia</pre></td></tr><tr><td data-num="54"></td><td><pre>    libcufft-10.7.2.124        <span class="token operator">|</span>       h4fbf590_0        <span class="token number">93.6</span> MB  nvidia</pre></td></tr><tr><td data-num="55"></td><td><pre>    libcufft-dev-10.7.2.124    <span class="token operator">|</span>       h98a8f43_0       <span class="token number">197.3</span> MB  nvidia</pre></td></tr><tr><td data-num="56"></td><td><pre>    libcufile-1.5.0.59         <span class="token operator">|</span>                <span class="token number">0</span>         <span class="token number">754</span> KB  nvidia</pre></td></tr><tr><td data-num="57"></td><td><pre>    libcufile-dev-1.5.0.59     <span class="token operator">|</span>                <span class="token number">0</span>          <span class="token number">13</span> KB  nvidia</pre></td></tr><tr><td data-num="58"></td><td><pre>    libcurand-10.3.1.50        <span class="token operator">|</span>                <span class="token number">0</span>        <span class="token number">51.7</span> MB  nvidia</pre></td></tr><tr><td data-num="59"></td><td><pre>    libcurand-dev-10.3.1.50    <span class="token operator">|</span>                <span class="token number">0</span>         <span class="token number">449</span> KB  nvidia</pre></td></tr><tr><td data-num="60"></td><td><pre>    libcusolver-11.4.0.1       <span class="token operator">|</span>                <span class="token number">0</span>        <span class="token number">78.7</span> MB  nvidia</pre></td></tr><tr><td data-num="61"></td><td><pre>    libcusolver-dev-11.4.0.1   <span class="token operator">|</span>                <span class="token number">0</span>        <span class="token number">55.9</span> MB  nvidia</pre></td></tr><tr><td data-num="62"></td><td><pre>    libcusparse-11.7.4.91      <span class="token operator">|</span>                <span class="token number">0</span>       <span class="token number">151.1</span> MB  nvidia</pre></td></tr><tr><td data-num="63"></td><td><pre>    libcusparse-dev-11.7.4.91  <span class="token operator">|</span>                <span class="token number">0</span>       <span class="token number">309.5</span> MB  nvidia</pre></td></tr><tr><td data-num="64"></td><td><pre>    libnpp-11.7.4.75           <span class="token operator">|</span>                <span class="token number">0</span>       <span class="token number">129.3</span> MB  nvidia</pre></td></tr><tr><td data-num="65"></td><td><pre>    libnpp-dev-11.7.4.75       <span class="token operator">|</span>                <span class="token number">0</span>       <span class="token number">126.6</span> MB  nvidia</pre></td></tr><tr><td data-num="66"></td><td><pre>    libnvjpeg-11.8.0.2         <span class="token operator">|</span>                <span class="token number">0</span>         <span class="token number">2.2</span> MB  nvidia</pre></td></tr><tr><td data-num="67"></td><td><pre>    libnvjpeg-dev-11.8.0.2     <span class="token operator">|</span>                <span class="token number">0</span>         <span class="token number">1.9</span> MB  nvidia</pre></td></tr><tr><td data-num="68"></td><td><pre>    mkl-2022.1.0               <span class="token operator">|</span>     hc2b9512_224       <span class="token number">129.7</span> MB</pre></td></tr><tr><td data-num="69"></td><td><pre>    ninja-1.10.2               <span class="token operator">|</span>       h06a4308_5           <span class="token number">8</span> KB</pre></td></tr><tr><td data-num="70"></td><td><pre>    ninja-base-1.10.2          <span class="token operator">|</span>       hd09550d_5         <span class="token number">109</span> KB</pre></td></tr><tr><td data-num="71"></td><td><pre>    nsight-compute-2022.4.0.15 <span class="token operator">|</span>                <span class="token number">0</span>       <span class="token number">764.0</span> MB  nvidia</pre></td></tr><tr><td data-num="72"></td><td><pre>    pillow-9.2.0               <span class="token operator">|</span>   py38hace64e9_1         <span class="token number">666</span> KB</pre></td></tr><tr><td data-num="73"></td><td><pre>    pytorch-1.4.0              <span class="token operator">|</span>py3.8_cuda10.1.243_cudnn7.6.3_0       <span class="token number">433.1</span> MB  pytorch</pre></td></tr><tr><td data-num="74"></td><td><pre>    pytorch-cuda-11.7          <span class="token operator">|</span>       h67b0de4_1           <span class="token number">3</span> KB  pytorch</pre></td></tr><tr><td data-num="75"></td><td><pre>    torchaudio-0.4.0           <span class="token operator">|</span>             py38         <span class="token number">6.1</span> MB  pytorch</pre></td></tr><tr><td data-num="76"></td><td><pre>    torchvision-0.5.0          <span class="token operator">|</span>       py38_cu101         <span class="token number">9.1</span> MB  pytorch</pre></td></tr><tr><td data-num="77"></td><td><pre>    ------------------------------------------------------------</pre></td></tr><tr><td data-num="78"></td><td><pre>                                           Total:        <span class="token number">3.91</span> GB</pre></td></tr><tr><td data-num="79"></td><td><pre></pre></td></tr><tr><td data-num="80"></td><td><pre>The following NEW packages will be INSTALLED:</pre></td></tr><tr><td data-num="81"></td><td><pre></pre></td></tr><tr><td data-num="82"></td><td><pre>  cuda               nvidia/linux-64::cuda-11.7.1-0</pre></td></tr><tr><td data-num="83"></td><td><pre>  cuda-cccl          nvidia/linux-64::cuda-cccl-11.7.91-0</pre></td></tr><tr><td data-num="84"></td><td><pre>  cuda-command-line~ nvidia/linux-64::cuda-command-line-tools-11.7.1-0</pre></td></tr><tr><td data-num="85"></td><td><pre>  cuda-compiler      nvidia/linux-64::cuda-compiler-11.7.1-0</pre></td></tr><tr><td data-num="86"></td><td><pre>  cuda-cudart        nvidia/linux-64::cuda-cudart-11.7.99-0</pre></td></tr><tr><td data-num="87"></td><td><pre>  cuda-cudart-dev    nvidia/linux-64::cuda-cudart-dev-11.7.99-0</pre></td></tr><tr><td data-num="88"></td><td><pre>  cuda-cuobjdump     nvidia/linux-64::cuda-cuobjdump-11.7.91-0</pre></td></tr><tr><td data-num="89"></td><td><pre>  cuda-cupti         nvidia/linux-64::cuda-cupti-11.7.101-0</pre></td></tr><tr><td data-num="90"></td><td><pre>  cuda-cuxxfilt      nvidia/linux-64::cuda-cuxxfilt-11.7.91-0</pre></td></tr><tr><td data-num="91"></td><td><pre>  cuda-demo-suite    nvidia/linux-64::cuda-demo-suite-12.0.76-0</pre></td></tr><tr><td data-num="92"></td><td><pre>  cuda-documentation nvidia/linux-64::cuda-documentation-12.0.76-0</pre></td></tr><tr><td data-num="93"></td><td><pre>  cuda-driver-dev    nvidia/linux-64::cuda-driver-dev-11.7.99-0</pre></td></tr><tr><td data-num="94"></td><td><pre>  cuda-gdb           nvidia/linux-64::cuda-gdb-12.0.90-0</pre></td></tr><tr><td data-num="95"></td><td><pre>  cuda-libraries     nvidia/linux-64::cuda-libraries-11.7.1-0</pre></td></tr><tr><td data-num="96"></td><td><pre>  cuda-libraries-dev nvidia/linux-64::cuda-libraries-dev-11.7.1-0</pre></td></tr><tr><td data-num="97"></td><td><pre>  cuda-memcheck      nvidia/linux-64::cuda-memcheck-11.8.86-0</pre></td></tr><tr><td data-num="98"></td><td><pre>  cuda-nsight        nvidia/linux-64::cuda-nsight-12.0.78-0</pre></td></tr><tr><td data-num="99"></td><td><pre>  cuda-nsight-compu~ nvidia/linux-64::cuda-nsight-compute-12.0.0-0</pre></td></tr><tr><td data-num="100"></td><td><pre>  cuda-nvcc          nvidia/linux-64::cuda-nvcc-11.7.99-0</pre></td></tr><tr><td data-num="101"></td><td><pre>  cuda-nvdisasm      nvidia/linux-64::cuda-nvdisasm-12.0.76-0</pre></td></tr><tr><td data-num="102"></td><td><pre>  cuda-nvml-dev      nvidia/linux-64::cuda-nvml-dev-11.7.91-0</pre></td></tr><tr><td data-num="103"></td><td><pre>  cuda-nvprof        nvidia/linux-64::cuda-nvprof-12.0.90-0</pre></td></tr><tr><td data-num="104"></td><td><pre>  cuda-nvprune       nvidia/linux-64::cuda-nvprune-11.7.91-0</pre></td></tr><tr><td data-num="105"></td><td><pre>  cuda-nvrtc         nvidia/linux-64::cuda-nvrtc-11.7.99-0</pre></td></tr><tr><td data-num="106"></td><td><pre>  cuda-nvrtc-dev     nvidia/linux-64::cuda-nvrtc-dev-11.7.99-0</pre></td></tr><tr><td data-num="107"></td><td><pre>  cuda-nvtx          nvidia/linux-64::cuda-nvtx-11.7.91-0</pre></td></tr><tr><td data-num="108"></td><td><pre>  cuda-nvvp          nvidia/linux-64::cuda-nvvp-12.0.90-0</pre></td></tr><tr><td data-num="109"></td><td><pre>  cuda-runtime       nvidia/linux-64::cuda-runtime-11.7.1-0</pre></td></tr><tr><td data-num="110"></td><td><pre>  cuda-sanitizer-api nvidia/linux-64::cuda-sanitizer-api-12.0.90-0</pre></td></tr><tr><td data-num="111"></td><td><pre>  cuda-toolkit       nvidia/linux-64::cuda-toolkit-11.7.1-0</pre></td></tr><tr><td data-num="112"></td><td><pre>  cuda-tools         nvidia/linux-64::cuda-tools-11.7.1-0</pre></td></tr><tr><td data-num="113"></td><td><pre>  cuda-visual-tools  nvidia/linux-64::cuda-visual-tools-11.7.1-0</pre></td></tr><tr><td data-num="114"></td><td><pre>  cudatoolkit        nvidia/linux-64::cudatoolkit-10.1.243-h036e899_8</pre></td></tr><tr><td data-num="115"></td><td><pre>  gds-tools          nvidia/linux-64::gds-tools-1.5.0.59-0</pre></td></tr><tr><td data-num="116"></td><td><pre>  intel-openmp       pkgs/main/linux-64::intel-openmp-2022.1.0-h9e868ea_3769</pre></td></tr><tr><td data-num="117"></td><td><pre>  lcms2              pkgs/main/linux-64::lcms2-2.12-h3be6417_0</pre></td></tr><tr><td data-num="118"></td><td><pre>  libcublas          nvidia/linux-64::libcublas-11.10.3.66-0</pre></td></tr><tr><td data-num="119"></td><td><pre>  libcublas-dev      nvidia/linux-64::libcublas-dev-11.10.3.66-0</pre></td></tr><tr><td data-num="120"></td><td><pre>  libcufft           nvidia/linux-64::libcufft-10.7.2.124-h4fbf590_0</pre></td></tr><tr><td data-num="121"></td><td><pre>  libcufft-dev       nvidia/linux-64::libcufft-dev-10.7.2.124-h98a8f43_0</pre></td></tr><tr><td data-num="122"></td><td><pre>  libcufile          nvidia/linux-64::libcufile-1.5.0.59-0</pre></td></tr><tr><td data-num="123"></td><td><pre>  libcufile-dev      nvidia/linux-64::libcufile-dev-1.5.0.59-0</pre></td></tr><tr><td data-num="124"></td><td><pre>  libcurand          nvidia/linux-64::libcurand-10.3.1.50-0</pre></td></tr><tr><td data-num="125"></td><td><pre>  libcurand-dev      nvidia/linux-64::libcurand-dev-10.3.1.50-0</pre></td></tr><tr><td data-num="126"></td><td><pre>  libcusolver        nvidia/linux-64::libcusolver-11.4.0.1-0</pre></td></tr><tr><td data-num="127"></td><td><pre>  libcusolver-dev    nvidia/linux-64::libcusolver-dev-11.4.0.1-0</pre></td></tr><tr><td data-num="128"></td><td><pre>  libcusparse        nvidia/linux-64::libcusparse-11.7.4.91-0</pre></td></tr><tr><td data-num="129"></td><td><pre>  libcusparse-dev    nvidia/linux-64::libcusparse-dev-11.7.4.91-0</pre></td></tr><tr><td data-num="130"></td><td><pre>  libnpp             nvidia/linux-64::libnpp-11.7.4.75-0</pre></td></tr><tr><td data-num="131"></td><td><pre>  libnpp-dev         nvidia/linux-64::libnpp-dev-11.7.4.75-0</pre></td></tr><tr><td data-num="132"></td><td><pre>  libnvjpeg          nvidia/linux-64::libnvjpeg-11.8.0.2-0</pre></td></tr><tr><td data-num="133"></td><td><pre>  libnvjpeg-dev      nvidia/linux-64::libnvjpeg-dev-11.8.0.2-0</pre></td></tr><tr><td data-num="134"></td><td><pre>  mkl                pkgs/main/linux-64::mkl-2022.1.0-hc2b9512_224</pre></td></tr><tr><td data-num="135"></td><td><pre>  ninja              pkgs/main/linux-64::ninja-1.10.2-h06a4308_5</pre></td></tr><tr><td data-num="136"></td><td><pre>  ninja-base         pkgs/main/linux-64::ninja-base-1.10.2-hd09550d_5</pre></td></tr><tr><td data-num="137"></td><td><pre>  nsight-compute     nvidia/linux-64::nsight-compute-2022.4.0.15-0</pre></td></tr><tr><td data-num="138"></td><td><pre>  pillow             pkgs/main/linux-64::pillow-9.2.0-py38hace64e9_1</pre></td></tr><tr><td data-num="139"></td><td><pre>  pytorch            pytorch/linux-64::pytorch-1.4.0-py3.8_cuda10.1.243_cudnn7.6.3_0</pre></td></tr><tr><td data-num="140"></td><td><pre>  pytorch-cuda       pytorch/noarch::pytorch-cuda-11.7-h67b0de4_1</pre></td></tr><tr><td data-num="141"></td><td><pre>  six                pkgs/main/noarch::six-1.16.0-pyhd3eb1b0_1</pre></td></tr><tr><td data-num="142"></td><td><pre>  torchaudio         pytorch/linux-64::torchaudio-0.4.0-py38</pre></td></tr><tr><td data-num="143"></td><td><pre>  torchvision        pytorch/linux-64::torchvision-0.5.0-py38_cu101</pre></td></tr></table></figure><p>贴一张安装过程中的截图哈哈</p><p>安装成功！用 <code>nvcc -V</code> 命令测试一下是否能正常输出，成功输出，如下图</p><p class="gallery" data-height="280"><img data-src="https://image.aayu.today/uploads/2022/12/18/202212182247894.png" alt=""><br><img data-src="https://image.aayu.today/uploads/2022/12/18/202212182327537.png" alt=""></p><p>导入 Pytorch 测试一下，正确链接到 GPU，并识别出显卡</p><p><img data-src="https://image.aayu.today/uploads/2022/12/19/202212190031485.png" alt="" width="800px"></p><h3 id="测试nvcc"><a class="anchor" href="#测试nvcc">#</a> 测试 Nvcc</h3><p>编写一个 cuda 脚本</p><figure class="highlight cpp"><figcaption data-lang="C++"><span>cuda_test_1.cu</span></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">include</span> <span class="token string">"cuda_runtime.h"</span></span></pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">include</span> <span class="token string">&lt;stdlib.h></span></span></pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">include</span> <span class="token string">&lt;assert.h></span></span></pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token macro property"><span class="token directive-hash">#</span><span class="token directive keyword">include</span> <span class="token string">&lt;iostream></span></span></pre></td></tr><tr><td data-num="5"></td><td><pre></pre></td></tr><tr><td data-num="6"></td><td><pre><span class="token comment">// Device code</span></pre></td></tr><tr><td data-num="7"></td><td><pre>__global__ <span class="token keyword">void</span> <span class="token function">VecAdd</span><span class="token punctuation">(</span><span class="token keyword">float</span><span class="token operator">*</span> A<span class="token punctuation">,</span> <span class="token keyword">float</span><span class="token operator">*</span> B<span class="token punctuation">,</span> <span class="token keyword">float</span><span class="token operator">*</span> C<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="8"></td><td><pre><span class="token punctuation">&#123;</span></pre></td></tr><tr><td data-num="9"></td><td><pre>    <span class="token keyword">int</span> i <span class="token operator">=</span> threadIdx<span class="token punctuation">.</span>x<span class="token punctuation">;</span></pre></td></tr><tr><td data-num="10"></td><td><pre>    C<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> A<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">+</span> B<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">;</span></pre></td></tr><tr><td data-num="11"></td><td><pre><span class="token punctuation">&#125;</span></pre></td></tr><tr><td data-num="12"></td><td><pre></pre></td></tr><tr><td data-num="13"></td><td><pre><span class="token comment">// Host code</span></pre></td></tr><tr><td data-num="14"></td><td><pre><span class="token keyword">int</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="15"></td><td><pre><span class="token punctuation">&#123;</span></pre></td></tr><tr><td data-num="16"></td><td><pre>    <span class="token keyword">int</span> N <span class="token operator">=</span> <span class="token number">1024</span><span class="token punctuation">;</span></pre></td></tr><tr><td data-num="17"></td><td><pre>    size_t size <span class="token operator">=</span> N <span class="token operator">*</span> <span class="token keyword">sizeof</span><span class="token punctuation">(</span><span class="token keyword">float</span><span class="token punctuation">)</span><span class="token punctuation">;</span></pre></td></tr><tr><td data-num="18"></td><td><pre></pre></td></tr><tr><td data-num="19"></td><td><pre>    <span class="token comment">// Allocate input vectors h_A and h_B in host memory</span></pre></td></tr><tr><td data-num="20"></td><td><pre>    <span class="token keyword">float</span><span class="token operator">*</span> h_A <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token keyword">float</span><span class="token operator">*</span><span class="token punctuation">)</span><span class="token function">malloc</span><span class="token punctuation">(</span>size<span class="token punctuation">)</span><span class="token punctuation">;</span></pre></td></tr><tr><td data-num="21"></td><td><pre>    <span class="token keyword">float</span><span class="token operator">*</span> h_B <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token keyword">float</span><span class="token operator">*</span><span class="token punctuation">)</span><span class="token function">malloc</span><span class="token punctuation">(</span>size<span class="token punctuation">)</span><span class="token punctuation">;</span></pre></td></tr><tr><td data-num="22"></td><td><pre>    <span class="token keyword">float</span><span class="token operator">*</span> h_C <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token keyword">float</span><span class="token operator">*</span><span class="token punctuation">)</span><span class="token function">malloc</span><span class="token punctuation">(</span>size<span class="token punctuation">)</span><span class="token punctuation">;</span></pre></td></tr><tr><td data-num="23"></td><td><pre></pre></td></tr><tr><td data-num="24"></td><td><pre>    <span class="token comment">// Initialize input vectors</span></pre></td></tr><tr><td data-num="25"></td><td><pre>    <span class="token keyword">for</span> <span class="token punctuation">(</span>size_t i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> N<span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="26"></td><td><pre>    <span class="token punctuation">&#123;</span></pre></td></tr><tr><td data-num="27"></td><td><pre>        h_A<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">1.</span><span class="token punctuation">;</span></pre></td></tr><tr><td data-num="28"></td><td><pre>        h_B<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">2.</span><span class="token punctuation">;</span></pre></td></tr><tr><td data-num="29"></td><td><pre>    <span class="token punctuation">&#125;</span></pre></td></tr><tr><td data-num="30"></td><td><pre></pre></td></tr><tr><td data-num="31"></td><td><pre>    <span class="token comment">// Allocate vectors in device memory</span></pre></td></tr><tr><td data-num="32"></td><td><pre>    <span class="token keyword">float</span><span class="token operator">*</span> d_A<span class="token punctuation">;</span></pre></td></tr><tr><td data-num="33"></td><td><pre>    <span class="token function">cudaMalloc</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>d_A<span class="token punctuation">,</span> size<span class="token punctuation">)</span><span class="token punctuation">;</span></pre></td></tr><tr><td data-num="34"></td><td><pre>    <span class="token keyword">float</span><span class="token operator">*</span> d_B<span class="token punctuation">;</span></pre></td></tr><tr><td data-num="35"></td><td><pre>    <span class="token function">cudaMalloc</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>d_B<span class="token punctuation">,</span> size<span class="token punctuation">)</span><span class="token punctuation">;</span></pre></td></tr><tr><td data-num="36"></td><td><pre>    <span class="token keyword">float</span><span class="token operator">*</span> d_C<span class="token punctuation">;</span></pre></td></tr><tr><td data-num="37"></td><td><pre>    <span class="token function">cudaMalloc</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>d_C<span class="token punctuation">,</span> size<span class="token punctuation">)</span><span class="token punctuation">;</span></pre></td></tr><tr><td data-num="38"></td><td><pre></pre></td></tr><tr><td data-num="39"></td><td><pre>    <span class="token comment">// Copy vectors from host memory to device memory</span></pre></td></tr><tr><td data-num="40"></td><td><pre>    <span class="token function">cudaMemcpy</span><span class="token punctuation">(</span>d_A<span class="token punctuation">,</span> h_A<span class="token punctuation">,</span> size<span class="token punctuation">,</span> cudaMemcpyHostToDevice<span class="token punctuation">)</span><span class="token punctuation">;</span></pre></td></tr><tr><td data-num="41"></td><td><pre>    <span class="token function">cudaMemcpy</span><span class="token punctuation">(</span>d_B<span class="token punctuation">,</span> h_B<span class="token punctuation">,</span> size<span class="token punctuation">,</span> cudaMemcpyHostToDevice<span class="token punctuation">)</span><span class="token punctuation">;</span></pre></td></tr><tr><td data-num="42"></td><td><pre></pre></td></tr><tr><td data-num="43"></td><td><pre>    <span class="token comment">// Kernel invocation with N threads</span></pre></td></tr><tr><td data-num="44"></td><td><pre>    VecAdd<span class="token operator">&lt;&lt;</span><span class="token operator">&lt;</span><span class="token number">1</span><span class="token punctuation">,</span> N<span class="token operator">>></span><span class="token operator">></span><span class="token punctuation">(</span>d_A<span class="token punctuation">,</span> d_B<span class="token punctuation">,</span> d_C<span class="token punctuation">)</span><span class="token punctuation">;</span></pre></td></tr><tr><td data-num="45"></td><td><pre></pre></td></tr><tr><td data-num="46"></td><td><pre>    <span class="token comment">// Copy result from device memory to host memory</span></pre></td></tr><tr><td data-num="47"></td><td><pre>    <span class="token comment">// h_C contains the result in host memory</span></pre></td></tr><tr><td data-num="48"></td><td><pre>    <span class="token function">cudaMemcpy</span><span class="token punctuation">(</span>h_C<span class="token punctuation">,</span> d_C<span class="token punctuation">,</span> size<span class="token punctuation">,</span> cudaMemcpyDeviceToHost<span class="token punctuation">)</span><span class="token punctuation">;</span></pre></td></tr><tr><td data-num="49"></td><td><pre>    <span class="token keyword">for</span> <span class="token punctuation">(</span>size_t i <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&lt;</span> N<span class="token punctuation">;</span> i<span class="token operator">++</span><span class="token punctuation">)</span><span class="token punctuation">&#123;</span></pre></td></tr><tr><td data-num="50"></td><td><pre>        <span class="token function">assert</span><span class="token punctuation">(</span>h_C<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">==</span> <span class="token number">3.</span><span class="token punctuation">)</span><span class="token punctuation">;</span></pre></td></tr><tr><td data-num="51"></td><td><pre>    <span class="token punctuation">&#125;</span></pre></td></tr><tr><td data-num="52"></td><td><pre>    std<span class="token double-colon punctuation">::</span>cout <span class="token operator">&lt;&lt;</span> <span class="token string">"\t\t\t\tDONE!"</span> <span class="token operator">&lt;&lt;</span> std<span class="token double-colon punctuation">::</span>endl<span class="token punctuation">;</span></pre></td></tr><tr><td data-num="53"></td><td><pre></pre></td></tr><tr><td data-num="54"></td><td><pre>    <span class="token comment">// Free device memory</span></pre></td></tr><tr><td data-num="55"></td><td><pre>    <span class="token function">cudaFree</span><span class="token punctuation">(</span>d_A<span class="token punctuation">)</span><span class="token punctuation">;</span></pre></td></tr><tr><td data-num="56"></td><td><pre>    <span class="token function">cudaFree</span><span class="token punctuation">(</span>d_B<span class="token punctuation">)</span><span class="token punctuation">;</span></pre></td></tr><tr><td data-num="57"></td><td><pre>    <span class="token function">cudaFree</span><span class="token punctuation">(</span>d_C<span class="token punctuation">)</span><span class="token punctuation">;</span></pre></td></tr><tr><td data-num="58"></td><td><pre></pre></td></tr><tr><td data-num="59"></td><td><pre>    <span class="token comment">// Free host memory</span></pre></td></tr><tr><td data-num="60"></td><td><pre>    <span class="token function">free</span><span class="token punctuation">(</span>h_A<span class="token punctuation">)</span><span class="token punctuation">;</span></pre></td></tr><tr><td data-num="61"></td><td><pre>    <span class="token function">free</span><span class="token punctuation">(</span>h_B<span class="token punctuation">)</span><span class="token punctuation">;</span></pre></td></tr><tr><td data-num="62"></td><td><pre>    <span class="token function">free</span><span class="token punctuation">(</span>h_C<span class="token punctuation">)</span><span class="token punctuation">;</span></pre></td></tr><tr><td data-num="63"></td><td><pre></pre></td></tr><tr><td data-num="64"></td><td><pre>    <span class="token keyword">return</span> <span class="token number">0</span><span class="token punctuation">;</span></pre></td></tr><tr><td data-num="65"></td><td><pre><span class="token punctuation">&#125;</span></pre></td></tr></table></figure><p>然后在刚刚安装了 cuda 的 python 环境下用以下命令编译</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre>nvcc cuda_test_1.cu -o cuda_test_1</pre></td></tr></table></figure><div class="note info"><p>如果报 <code>gcc: No such file or directory</code> ，则需要用如下命令安装 gcc 及调试工具</p><figure class="highlight bash"><figcaption data-lang="bash"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token function">sudo</span> <span class="token function">apt</span> <span class="token function">install</span> build-essential gdb</pre></td></tr></table></figure><p>安装完成后用 <code>gcc --version</code> 测试一下，由正常输出即安装成功</p></div><p>编译成功后用 <code>./cuda_test_1</code> 运行，成功运行如下图</p><p><img data-src="https://image.aayu.today/uploads/2022/12/19/202212191538223.png" alt="" width="800px"></p><p>大功告成！</p><h2 id="参考链接"><a class="anchor" href="#参考链接">#</a> 参考链接</h2><ul><li><span class="exturl" data-url="aHR0cHM6Ly93d3cuYmlsaWJpbGkuY29tL3JlYWQvY3YxNDYwODU0Nw==">Windows10/11 WSL2 安装 nvidia-cuda 驱动</span></li><li><span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2l3YW52YW4vYXJ0aWNsZS9kZXRhaWxzLzEyMjExOTU5NQ==">Windows 11/10 WSL2 Ubuntu 20.04 下配置 Cuda 及 Pytorch</span></li><li><span class="exturl" data-url="aHR0cHM6Ly93d3cuYmlsaWJpbGkuY29tL3ZpZGVvL0JWMTVRNHkxaTdCcC8/cD0y">【PyTorch】B 站首个，终于有人把 GPU/ CUDA/cuDNN 讲清楚了</span></li><li><span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2d0ZjIxNTk5ODMxNS9hcnRpY2xlL2RldGFpbHMvMTA1MzU5NzQz">【资源记录】各个历史版本 cuda toolkit 下载链接</span></li></ul><div class="tags"><a href="/tags/win11/" rel="tag"><i class="ic i-tag"></i> win11</a> <a href="/tags/wsl/" rel="tag"><i class="ic i-tag"></i> wsl</a> <a href="/tags/nvidia/" rel="tag"><i class="ic i-tag"></i> nvidia</a></div></div><footer><div class="meta"><span class="item"><span class="icon"><i class="ic i-calendar-check"></i> </span><span class="text">更新于</span> <time title="修改时间：2023-10-02 23:52:51" itemprop="dateModified" datetime="2023-10-02T23:52:51+08:00">2023-10-02</time> </span><span id="artificial-intelligence/basic/20221217/" class="item leancloud_visitors" data-flag-title="Win11安装WSL2和Nvidia驱动" title="阅读次数"><span class="icon"><i class="ic i-eye"></i> </span><span class="text">阅读次数</span> <span class="leancloud-visitors-count"></span> <span class="text">次</span></span></div><div class="reward"><button><i class="ic i-heartbeat"></i> 赞赏</button><p>请我喝[茶]~(￣▽￣)~*</p><div id="qr"><div><img data-src="/images/wechatpay.png" alt="宇凌喵 微信支付"><p>微信支付</p></div><div><img data-src="/images/alipay.png" alt="宇凌喵 支付宝"><p>支付宝</p></div></div></div><div id="copyright"><ul><li class="author"><strong>本文作者： </strong>宇凌喵 <i class="ic i-at"><em>@</em></i>学无止境</li><li class="link"><strong>本文链接：</strong> <a href="https://blog.aayu.today/artificial-intelligence/basic/20221217/" title="Win11安装WSL2和Nvidia驱动">https://blog.aayu.today/artificial-intelligence/basic/20221217/</a></li><li class="license"><strong>版权声明： </strong>本站所有文章除特别声明外，均采用 <span class="exturl" data-url="aHR0cHM6Ly9jcmVhdGl2ZWNvbW1vbnMub3JnL2xpY2Vuc2VzL2J5LW5jLXNhLzQuMC9kZWVkLnpo"><i class="ic i-creative-commons"><em>(CC)</em></i>BY-NC-SA</span> 许可协议。转载请注明出处！</li></ul></div></footer></article></div><div class="post-nav"><div class="item left"><a href="/artificial-intelligence/basic/20221207/" itemprop="url" rel="prev" data-background-image="https:&#x2F;&#x2F;image.aayu.today&#x2F;uploads&#x2F;2022&#x2F;12&#x2F;28&#x2F;6833939bly1giclwuom7cj20zk0m8dvn.jpg" title="VSCode配置C++和Python编译和调试环境"><span class="type">上一篇</span> <span class="category"><i class="ic i-flag"></i> 基础知识</span><h3>VSCode配置C++和Python编译和调试环境</h3></a></div><div class="item right"><a href="/artificial-intelligence/machine-learning/bn/20230101/" itemprop="url" rel="next" data-background-image="https:&#x2F;&#x2F;image.aayu.today&#x2F;uploads&#x2F;2023&#x2F;08&#x2F;07&#x2F;202308072351935.png" title="贝叶斯网络"><span class="type">下一篇</span> <span class="category"><i class="ic i-flag"></i> 贝叶斯网络</span><h3>贝叶斯网络</h3></a></div></div><div class="wrap" id="comments"></div></div><div id="sidebar"><div class="inner"><div class="panels"><div class="inner"><div class="contents panel pjax" data-title="文章目录"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%89%8D%E8%A8%80"><span class="toc-number">1.</span> <span class="toc-text">前言</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%B3%BB%E7%BB%9F%E7%8E%AF%E5%A2%83"><span class="toc-number">2.</span> <span class="toc-text">系统环境</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#wsl-1%E5%92%8Cwsl-2%E5%8A%9F%E8%83%BD%E5%AF%B9%E6%AF%94"><span class="toc-number">3.</span> <span class="toc-text">WSL 1 和 WSL 2 功能对比</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%89%E8%A3%85wsl2"><span class="toc-number">4.</span> <span class="toc-text">安装 WSL2</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%9B%B4%E6%96%B0%E5%92%8C%E5%8D%87%E7%BA%A7%E5%8C%85"><span class="toc-number">5.</span> <span class="toc-text">更新和升级包</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%85%8D%E7%BD%AEvscode"><span class="toc-number">6.</span> <span class="toc-text">配置 VSCode</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%85%8D%E7%BD%AEminiconda"><span class="toc-number">7.</span> <span class="toc-text">配置 MiniConda</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%89%E8%A3%85miniconda"><span class="toc-number">7.1.</span> <span class="toc-text">安装 MiniConda</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%85%8D%E7%BD%AEminiconda-2"><span class="toc-number">7.2.</span> <span class="toc-text">配置 MiniConda</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#pip%E6%8D%A2%E5%9B%BD%E5%86%85%E6%BA%90linux%E7%8E%AF%E5%A2%83"><span class="toc-number">8.</span> <span class="toc-text">pip 换国内源（Linux 环境）</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%B4%E6%97%B6%E6%8D%A2%E6%BA%90%E4%B8%8D%E6%8E%A8%E8%8D%90"><span class="toc-number">8.1.</span> <span class="toc-text">临时换源（不推荐）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B0%B8%E4%B9%85%E6%8D%A2%E6%BA%90%E6%8E%A8%E8%8D%90"><span class="toc-number">8.2.</span> <span class="toc-text">永久换源（推荐）</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%85%8D%E7%BD%AEgpu%E5%8A%A0%E9%80%9F"><span class="toc-number">9.</span> <span class="toc-text">配置 GPU 加速</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%89%E8%A3%85nvidia%E9%A9%B1%E5%8A%A8"><span class="toc-number">9.1.</span> <span class="toc-text">安装 Nvidia 驱动</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%89%E8%A3%85cuda-toolkit"><span class="toc-number">9.2.</span> <span class="toc-text">安装 Cuda Toolkit</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E9%80%9A%E8%BF%87pytorch%E5%AE%89%E8%A3%85cuda-toolkit"><span class="toc-number">9.2.1.</span> <span class="toc-text">通过 PyTorch 安装 CUDA Toolkit</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B5%8B%E8%AF%95nvcc"><span class="toc-number">9.3.</span> <span class="toc-text">测试 Nvcc</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5"><span class="toc-number">10.</span> <span class="toc-text">参考链接</span></a></li></ol></div><div class="related panel pjax" data-title="系列文章"><ul><li><a href="/artificial-intelligence/basic/20221027/" rel="bookmark" title="Python环境配置">Python环境配置</a></li><li><a href="/artificial-intelligence/basic/20221028/" rel="bookmark" title="用Python理解图像和视频的本质">用Python理解图像和视频的本质</a></li><li><a href="/artificial-intelligence/basic/20221207/" rel="bookmark" title="VSCode配置C++和Python编译和调试环境">VSCode配置C++和Python编译和调试环境</a></li><li class="active"><a href="/artificial-intelligence/basic/20221217/" rel="bookmark" title="Win11安装WSL2和Nvidia驱动">Win11安装WSL2和Nvidia驱动</a></li><li><a href="/artificial-intelligence/basic/20230207/" rel="bookmark" title="WSL2通过OpenCV调用并展示本机摄像头的RTSP视频流">WSL2通过OpenCV调用并展示本机摄像头的RTSP视频流</a></li><li><a href="/artificial-intelligence/basic/20230208/" rel="bookmark" title="Win11基于WSL2安装CUDA、cuDNN和TensorRT">Win11基于WSL2安装CUDA、cuDNN和TensorRT</a></li><li><a href="/artificial-intelligence/basic/20230720/" rel="bookmark" title="Matplotlib学习笔记">Matplotlib学习笔记</a></li><li><a href="/artificial-intelligence/basic/20230725/" rel="bookmark" title="K折交叉验证和F1-Score学习笔记">K折交叉验证和F1-Score学习笔记</a></li></ul></div><div class="overview panel" data-title="站点概览"><div class="author" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="image" itemprop="image" alt="宇凌喵" data-src="/images/avatar.jpg"><p class="name" itemprop="name">宇凌喵</p><div class="description" itemprop="description">真理和热爱是吾永生的追求</div></div><nav class="state"><div class="item posts"><a href="/archives/"><span class="count">368</span> <span class="name">文章</span></a></div><div class="item categories"><a href="/categories/"><span class="count">98</span> <span class="name">分类</span></a></div><div class="item tags"><a href="/tags/"><span class="count">131</span> <span class="name">标签</span></a></div></nav><div class="social"><span class="exturl item github" data-url="aHR0cHM6Ly9naXRodWIuY29tL3lsc2lzbG92ZQ==" title="https:&#x2F;&#x2F;github.com&#x2F;ylsislove"><i class="ic i-github"></i></span> <span class="exturl item weibo" data-url="aHR0cHM6Ly93ZWliby5jb20veW91cm5hbWU=" title="https:&#x2F;&#x2F;weibo.com&#x2F;yourname"><i class="ic i-weibo"></i></span> <span class="exturl item email" data-url="bWFpbHRvOjkxNjQ5MTAxM0BxcS5jb20=" title="mailto:916491013@qq.com"><i class="ic i-envelope"></i></span></div><ul class="menu"><li class="item"><a href="/" rel="section"><i class="ic i-home"></i>首页</a></li><li class="item"><a href="/about/" rel="section"><i class="ic i-user"></i>关于</a></li><li class="item dropdown"><a href="javascript:void(0);"><i class="ic i-feather"></i>文章</a><ul class="submenu"><li class="item"><a href="/archives/" rel="section"><i class="ic i-list-alt"></i>归档</a></li><li class="item"><a href="/categories/" rel="section"><i class="ic i-th"></i>分类</a></li><li class="item"><a href="/tags/" rel="section"><i class="ic i-tags"></i>标签</a></li></ul></li><li class="item dropdown"><a href="javascript:void(0);"><i class="ic i-magic"></i>链环</a><ul class="submenu"><li class="item"><a href="/friends/" rel="section"><i class="ic i-heart"></i>友達</a></li><li class="item"><a href="/webstack/" rel="section"><i class="ic i-star"></i>网址</a></li></ul></li><li class="item"><span class="exturl" data-url="aHR0cHM6Ly9mb3JldmVyYmxvZy5jbi9nby5odG1s"><i class="ic i-paper-plane"></i>虫洞</span></li></ul></div></div></div><ul id="quick"><li class="prev pjax"><a href="/artificial-intelligence/basic/20221207/" rel="prev" title="上一篇"><i class="ic i-chevron-left"></i></a></li><li class="up"><i class="ic i-arrow-up"></i></li><li class="down"><i class="ic i-arrow-down"></i></li><li class="next pjax"><a href="/artificial-intelligence/machine-learning/bn/20230101/" rel="next" title="下一篇"><i class="ic i-chevron-right"></i></a></li><li class="percent"></li></ul></div></div><div class="dimmer"></div></div></main><footer id="footer"><div class="inner"><div class="widgets"><div class="rpost pjax"><h2>随机文章</h2><ul><li class="item"><div class="breadcrumb"><a href="/categories/artificial-intelligence/" title="分类于 人工智能">人工智能</a> <i class="ic i-angle-right"></i> <a href="/categories/artificial-intelligence/webrtc/" title="分类于 WebRTC">WebRTC</a></div><span><a href="/artificial-intelligence/webrtc/20210329/" title="Web-内网穿透NAT类型判断">Web-内网穿透NAT类型判断</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/database/" title="分类于 数据库">数据库</a> <i class="ic i-angle-right"></i> <a href="/categories/database/postgresql/" title="分类于 PostgreSQL">PostgreSQL</a></div><span><a href="/database/postgresql/20210913/" title="Docker创建PostgreSQL数据库并导入矢量数据">Docker创建PostgreSQL数据库并导入矢量数据</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/computer-graphics/" title="分类于 计算机图形学">计算机图形学</a> <i class="ic i-angle-right"></i> <a href="/categories/computer-graphics/shader/" title="分类于 Shader">Shader</a> <i class="ic i-angle-right"></i> <a href="/categories/computer-graphics/shader/unity-shader/" title="分类于 Unity Shader">Unity Shader</a></div><span><a href="/computer-graphics/shader/unity-shader/20210427-2/" title="Shader-UnityShader属性块介绍">Shader-UnityShader属性块介绍</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/artificial-intelligence/" title="分类于 人工智能">人工智能</a> <i class="ic i-angle-right"></i> <a href="/categories/artificial-intelligence/pytorch/" title="分类于 机器学习修炼之PyTorch">机器学习修炼之PyTorch</a></div><span><a href="/artificial-intelligence/pytorch/20200610/" title="Pytorch-多输出回归任务实战（二）">Pytorch-多输出回归任务实战（二）</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/artificial-intelligence/" title="分类于 人工智能">人工智能</a> <i class="ic i-angle-right"></i> <a href="/categories/artificial-intelligence/machine-learning/" title="分类于 机器学习">机器学习</a> <i class="ic i-angle-right"></i> <a href="/categories/artificial-intelligence/machine-learning/hmm/" title="分类于 隐马尔可夫模型">隐马尔可夫模型</a></div><span><a href="/artificial-intelligence/machine-learning/hmm/20221207/" title="隐马尔科夫模型">隐马尔科夫模型</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/feature/" title="分类于 HoloLens2开发笔记">HoloLens2开发笔记</a> <i class="ic i-angle-right"></i> <a href="/categories/feature/crash-recovery/" title="分类于 故障修复">故障修复</a></div><span><a href="/feature/crash-recovery/20210310/" title="Hololens2-MixedReality-WebRTC的使用问题">Hololens2-MixedReality-WebRTC的使用问题</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/hardware/" title="分类于 硬件修炼手册">硬件修炼手册</a> <i class="ic i-angle-right"></i> <a href="/categories/hardware/bear-pi/" title="分类于 小熊派">小熊派</a></div><span><a href="/hardware/bear-pi/20211009/" title="小熊派-点亮LED灯（基于STM32CubeMX）">小熊派-点亮LED灯（基于STM32CubeMX）</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/hardware/" title="分类于 硬件修炼手册">硬件修炼手册</a> <i class="ic i-angle-right"></i> <a href="/categories/hardware/raspberry-pi/" title="分类于 树莓派">树莓派</a></div><span><a href="/hardware/raspberry-pi/20210901/" title="树莓派-继电器模块控制实验">树莓派-继电器模块控制实验</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/english/" title="分类于 英语学习之路">英语学习之路</a> <i class="ic i-angle-right"></i> <a href="/categories/english/ielts/" title="分类于 雅思备战">雅思备战</a></div><span><a href="/english/ielts/20200710/" title="雅思写作-讨论类话题综述">雅思写作-讨论类话题综述</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/english/" title="分类于 英语学习之路">英语学习之路</a> <i class="ic i-angle-right"></i> <a href="/categories/english/%E8%AF%AD%E6%B3%95%E5%AD%A6%E4%B9%A0/" title="分类于 语法学习">语法学习</a></div><span><a href="/english/grammar/20221005/" title="英语语法学习（3）：动词时态">英语语法学习（3）：动词时态</a></span></li></ul></div><div><h2>最新评论</h2><ul class="leancloud-recent-comment"></ul></div></div><div class="status"><div class="copyright">&copy; 2020 – <span itemprop="copyrightYear">2023</span> <span class="with-love"><i class="ic i-sakura rotate"></i> </span><span class="author" itemprop="copyrightHolder">宇凌喵 @ Aayu Yain</span></div><div class="count"><span class="post-meta-item-icon"><i class="ic i-chart-area"></i> </span><span title="站点总字数">779k 字</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="ic i-coffee"></i> </span><span title="站点阅读时长">11:48</span> <span class="beian"><i class="ic i-beian1"></i> </span><span>晋ICP备19006357号-4</span></div><div class="powered-by">基于 <span class="exturl" data-url="aHR0cHM6Ly9oZXhvLmlv">Hexo</span> & Theme.<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2FtZWhpbWUvaGV4by10aGVtZS1zaG9rYQ==">Shoka</span></div></div></div></footer></div><script data-config type="text/javascript">var LOCAL={path:"artificial-intelligence/basic/20221217/",favicon:{show:"（●´3｀●）やれやれだぜ",hide:"(´Д｀)大変だ！"},search:{placeholder:"文章搜索",empty:"关于 「 ${query} 」，什么也没搜到",stats:"${time} ms 内找到 ${hits} 条结果"},valine:!0,fancybox:!0,copyright:'复制成功，转载请遵守 <i class="ic i-creative-commons"></i>BY-NC-SA 协议。',ignores:[function(i){return i.includes("#")},function(i){return new RegExp(LOCAL.path+"$").test(i)}]}</script><script src="assets/polyfill.js"></script><script src="/assets/quicklink.umd.js"></script><script src="/js/app.js?v=0.2.5"></script></body></html><!-- rebuild by hrmmi -->