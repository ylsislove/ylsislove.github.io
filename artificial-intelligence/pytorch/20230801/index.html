<!-- build time:Sat Aug 31 2024 01:59:00 GMT+0800 (China Standard Time) --><!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#FFF"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png"><link rel="icon" type="image/ico" sizes="32x32" href="/images/favicon.ico"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="alternate" type="application/rss+xml" title="学无止境" href="https://blog.aayu.today/rss.xml"><link rel="alternate" type="application/atom+xml" title="学无止境" href="https://blog.aayu.today/atom.xml"><link rel="alternate" type="application/json" title="学无止境" href="https://blog.aayu.today/feed.json"><link rel="stylesheet" href="/assets/fonts.googleapis.com.css"><link rel="stylesheet" href="/css/app.css?v=0.2.5"><meta name="keywords" content="PyTorch"><link rel="canonical" href="https://blog.aayu.today/artificial-intelligence/pytorch/20230801/"><title>PyTorch学习笔记（11）自编码器Auto-Encoders - 机器学习修炼之PyTorch - 人工智能 | Aayu Yain = 学无止境 = 世界上大部分事，都没太大意义。真理与热爱除外</title><meta name="generator" content="Hexo 5.4.2"></head><body itemscope itemtype="http://schema.org/WebPage"><div id="loading"><div class="cat"><div class="body"></div><div class="head"><div class="face"></div></div><div class="foot"><div class="tummy-end"></div><div class="bottom"></div><div class="legs left"></div><div class="legs right"></div></div><div class="paw"><div class="hands left"></div><div class="hands right"></div></div></div></div><div id="container"><header id="header" itemscope itemtype="http://schema.org/WPHeader"><div class="inner"><div id="brand"><div class="pjax"><h1 itemprop="name headline">PyTorch学习笔记（11）自编码器Auto-Encoders</h1><div class="meta"><span class="item" title="创建时间：2023-08-01 16:19:10"><span class="icon"><i class="ic i-calendar"></i> </span><span class="text">发表于</span> <time itemprop="dateCreated datePublished" datetime="2023-08-01T16:19:10+08:00">2023-08-01</time> </span><span class="item" title="本文字数"><span class="icon"><i class="ic i-pen"></i> </span><span class="text">本文字数</span> <span>3.9k</span> <span class="text">字</span> </span><span class="item" title="阅读时长"><span class="icon"><i class="ic i-clock"></i> </span><span class="text">阅读时长</span> <span>4 分钟</span></span></div></div></div><nav id="nav"><div class="inner"><div class="toggle"><div class="lines" aria-label="切换导航栏"><span class="line"></span> <span class="line"></span> <span class="line"></span></div></div><ul class="menu"><li class="item title"><a href="/" rel="start">Aayu Yain</a></li></ul><ul class="right"><li class="item theme"><i class="ic i-sun"></i></li><li class="item search"><i class="ic i-search"></i></li></ul></div></nav></div><div id="imgs" class="pjax"><ul><li class="item" data-background-image="https://image.aayu.today/uploads/2022/12/28/6833939bly1gipewr8iypj20zk0m8b29.jpg"></li><li class="item" data-background-image="https://image.aayu.today/uploads/2022/12/28/6833939bly1gicliierfjj20zk0m8npd.jpg"></li><li class="item" data-background-image="https://image.aayu.today/uploads/2022/12/28/6833939bly1giclh0m9pdj20zk0m8hdt.jpg"></li><li class="item" data-background-image="https://image.aayu.today/uploads/2022/12/28/6833939bly1gicit31ffoj20zk0m8naf.jpg"></li><li class="item" data-background-image="https://image.aayu.today/uploads/2022/12/28/6833939bly1gipeuv80yoj20zk0m8kjl.jpg"></li><li class="item" data-background-image="https://image.aayu.today/uploads/2022/12/28/6833939bly1gicljitigmj20zk0m87fp.jpg"></li></ul></div></header><div id="waves"><svg class="waves" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 24 150 28" preserveAspectRatio="none" shape-rendering="auto"><defs><path id="gentle-wave" d="M-160 44c30 0 58-18 88-18s 58 18 88 18 58-18 88-18 58 18 88 18 v44h-352z"/></defs><g class="parallax"><use xlink:href="#gentle-wave" x="48" y="0"/><use xlink:href="#gentle-wave" x="48" y="3"/><use xlink:href="#gentle-wave" x="48" y="5"/><use xlink:href="#gentle-wave" x="48" y="7"/></g></svg></div><main><div class="inner"><div id="main" class="pjax"><div class="article wrap"><div class="breadcrumb" itemscope itemtype="https://schema.org/BreadcrumbList"><i class="ic i-home"></i> <span><a href="/">首页</a></span><i class="ic i-angle-right"></i> <span itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a href="/categories/artificial-intelligence/" itemprop="item" rel="index" title="分类于 人工智能"><span itemprop="name">人工智能</span></a><meta itemprop="position" content="1"></span><i class="ic i-angle-right"></i> <span class="current" itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a href="/categories/artificial-intelligence/pytorch/" itemprop="item" rel="index" title="分类于 机器学习修炼之PyTorch"><span itemprop="name">机器学习修炼之PyTorch</span></a><meta itemprop="position" content="2"></span></div><article itemscope itemtype="http://schema.org/Article" class="post block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://blog.aayu.today/artificial-intelligence/pytorch/20230801/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.jpg"><meta itemprop="name" content="宇凌喵"><meta itemprop="description" content="世界上大部分事，都没太大意义。真理与热爱除外, 真理和热爱是吾永生的追求"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="学无止境"></span><div class="body md" itemprop="articleBody"><p>前面所接触的一般都是监督学习，而除了有监督学习，互联网上更多的数据都是没有标签的，所以这就引出了无监督学习。</p><p>无监督学习不是没有标签，而是数据本身就是标签，通过神经网络找出数据内在的特征，然后再重构出数据本身，这就是自编码器 Auto-Encoders</p><p><img data-src="assets/image-20230801151818-rmzm1kv.png" alt="image"></p><p>这个过程其实就是要找到数据本质的特征，和 PCA 降维类似，通过 Auto-Encoders 找到降维后的特征后，我们就可以方便的将其可视化出来了，比如这个比较著名的可视化网站：<span class="exturl" data-url="aHR0cHM6Ly9wcm9qZWN0b3IudGVuc29yZmxvdy5vcmcv">Embedding projector - visualization of high-dimensional data (tensorflow.org)</span></p><p><img data-src="assets/image-20230801153030-36uhepi.png" alt="image"></p><h2 id="pca-vs-auto-encoders"><a class="anchor" href="#pca-vs-auto-encoders">#</a> PCA V.S. Auto-Encoders</h2><p><img data-src="assets/image-20230801152041-3k1mws2.png" alt="image"></p><p>可以看到 Auto-Encoders 重建出来的数据效果还是明显优于 PCA 的</p><h2 id="auto-encoders-变种"><a class="anchor" href="#auto-encoders-变种">#</a> Auto-Encoders 变种</h2><h3 id="denoising-autoencoders"><a class="anchor" href="#denoising-autoencoders">#</a> Denoising AutoEncoders</h3><p>为了防止神经网络记住训练数据集，所以在训练数据中添加一个高斯噪声，逼迫神经网络真正学到数据的特征。</p><p><img data-src="assets/image-20230801152438-cvpx96c.png" alt="image"></p><h3 id="dropout-autoencoders"><a class="anchor" href="#dropout-autoencoders">#</a> Dropout AutoEncoders</h3><p>同样也是为了防止过拟合，所以添加一个适当的 Dropout，可以提升测试集上的准确率，如最右边的图</p><p><img data-src="assets/image-20230801152522-dwcyme2.png" alt="image"></p><h3 id="adversarial-autoencoders"><a class="anchor" href="#adversarial-autoencoders">#</a> Adversarial AutoEncoders</h3><p>如果将隐藏层的数据分布可视化出来，可以发现它的分布是有偏的，如下</p><p><img data-src="assets/image-20230801153221-zf643tv.png" alt="image"></p><p><img data-src="assets/image-20230801153349-8pu8044.png" alt="image"></p><p>所以我们也想尽可能将这个分布也学习到，就借鉴 GAN 的思想，引入一个鉴别器，专门用来学习隐藏层的分布</p><h2 id="variational-autoencoders"><a class="anchor" href="#variational-autoencoders">#</a> Variational AutoEncoders</h2><blockquote><p>相关资料：<span class="exturl" data-url="aHR0cHM6Ly93d3cuamVyZW15am9yZGFuLm1lL3ZhcmlhdGlvbmFsLWF1dG9lbmNvZGVycy8=">Variational autoencoders. (jeremyjordan.me)</span></p></blockquote><p>KL 散度，用来衡量两个分布间的差异，详情：<span class="exturl" data-url="aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC8xMDA2NzY5MjI=">Kullback-Leibler (KL) 散度介绍</span></p><p>所以和上面的 Adversarial AutoEncoders 类似，变分自编码器通过 KL 散度来学习隐藏层的分布，如下</p><p><img data-src="assets/image-20230801154305-535hiuc.png" alt="image"></p><p>可以看到公式中被加号分为了两个部分，第一部分就是希望模型尽可能的学习到特征 z，然后通过特征 z 再重构出 x</p><p>第二部分就是 KL 散度的计算，KL 散度越小，表示两个分布之间的差异越小，所以第二部分就希望模型尽可能学习到特征的分布</p><p><img data-src="assets/image-20230801154737-c08y2eb.png" alt="image"></p><p><img data-src="assets/image-20230801154805-j3ud22y.png" alt="image"></p><h3 id="kl-散度的计算"><a class="anchor" href="#kl-散度的计算">#</a> KL 散度的计算</h3><blockquote><p>参考：<span class="exturl" data-url="aHR0cHM6Ly9zdGF0cy5zdGFja2V4Y2hhbmdlLmNvbS9xdWVzdGlvbnMvNzQ0MC9rbC1kaXZlcmdlbmNlLWJldHdlZW4tdHdvLXVuaXZhcmlhdGUtZ2F1c3NpYW5z">normal distribution - KL divergence between two univariate Gaussians - Cross Validated (stackexchange.com)</span></p></blockquote><p><img data-src="assets/image-20230801155111-x095j0k.png" alt="image"></p><h3 id="reparameterization-trick"><a class="anchor" href="#reparameterization-trick">#</a> Reparameterization trick</h3><p>因为现在隐藏层变成了一个分布，所以需要从分布中进行取样，但取样又会造成无法求梯度的问题，也就是无法反向传播，所以，使用一个小 trick，如下</p><p><img data-src="assets/image-20230801155404-c5pq8up.png" alt="image"></p><p><img data-src="assets/image-20230801155421-xgqaw8t.png" alt="image"></p><p>将取样的过程拆除出来，模型反向传播的过程就可以避开它，从而可以优化参数 μ 和 σ</p><p><img data-src="assets/image-20230801155717-3kufzk7.png" alt="image"></p><h3 id="应用"><a class="anchor" href="#应用">#</a> 应用</h3><p>通过在分布上取样不同的点，就可以调整生成的结果，如下</p><p><img data-src="assets/image-20230801155905-7ndts4c.png" alt="image"></p><p>这和 GAN 类似，但实际上自编码器还是重建的是数据本身，无法自己创造出新的数据，而且重建的数据效果也往往没有 GAN 好</p><p><img data-src="assets/image-20230801160134-hv7y0bw.png" alt="image"></p><p>左边是变分自编码器，右边是 GAN</p><h2 id="代码实战"><a class="anchor" href="#代码实战">#</a> 代码实战</h2><h3 id="auto-encoders-代码"><a class="anchor" href="#auto-encoders-代码">#</a> Auto-Encoders 代码</h3><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">import</span>  torch</pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token keyword">from</span>    torch <span class="token keyword">import</span> nn</pre></td></tr><tr><td data-num="3"></td><td><pre></pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token keyword">class</span> <span class="token class-name">AE</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="5"></td><td><pre></pre></td></tr><tr><td data-num="6"></td><td><pre>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="7"></td><td><pre>        <span class="token builtin">super</span><span class="token punctuation">(</span>AE<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="8"></td><td><pre></pre></td></tr><tr><td data-num="9"></td><td><pre></pre></td></tr><tr><td data-num="10"></td><td><pre>        <span class="token comment"># [b, 784] => [b, 20]</span></pre></td></tr><tr><td data-num="11"></td><td><pre>        self<span class="token punctuation">.</span>encoder <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span></pre></td></tr><tr><td data-num="12"></td><td><pre>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">784</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">)</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="13"></td><td><pre>            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="14"></td><td><pre>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">)</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="15"></td><td><pre>            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="16"></td><td><pre>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">)</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="17"></td><td><pre>            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="18"></td><td><pre>        <span class="token punctuation">)</span></pre></td></tr><tr><td data-num="19"></td><td><pre>        <span class="token comment"># [b, 20] => [b, 784]</span></pre></td></tr><tr><td data-num="20"></td><td><pre>        self<span class="token punctuation">.</span>decoder <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span></pre></td></tr><tr><td data-num="21"></td><td><pre>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">)</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="22"></td><td><pre>            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="23"></td><td><pre>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">)</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="24"></td><td><pre>            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="25"></td><td><pre>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">784</span><span class="token punctuation">)</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="26"></td><td><pre>            nn<span class="token punctuation">.</span>Sigmoid<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="27"></td><td><pre>        <span class="token punctuation">)</span></pre></td></tr><tr><td data-num="28"></td><td><pre></pre></td></tr><tr><td data-num="29"></td><td><pre></pre></td></tr><tr><td data-num="30"></td><td><pre>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="31"></td><td><pre>        <span class="token triple-quoted-string string">"""</span></pre></td></tr><tr><td data-num="32"></td><td><pre></pre></td></tr><tr><td data-num="33"></td><td><pre>        :param x: [b, 1, 28, 28]</pre></td></tr><tr><td data-num="34"></td><td><pre>        :return:</pre></td></tr><tr><td data-num="35"></td><td><pre>        """</pre></td></tr><tr><td data-num="36"></td><td><pre>        batchsz <span class="token operator">=</span> x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="37"></td><td><pre>        <span class="token comment"># flatten</span></pre></td></tr><tr><td data-num="38"></td><td><pre>        x <span class="token operator">=</span> x<span class="token punctuation">.</span>view<span class="token punctuation">(</span>batchsz<span class="token punctuation">,</span> <span class="token number">784</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="39"></td><td><pre>        <span class="token comment"># encoder</span></pre></td></tr><tr><td data-num="40"></td><td><pre>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>encoder<span class="token punctuation">(</span>x<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="41"></td><td><pre>        <span class="token comment"># decoder</span></pre></td></tr><tr><td data-num="42"></td><td><pre>        x <span class="token operator">=</span> self<span class="token punctuation">.</span>decoder<span class="token punctuation">(</span>x<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="43"></td><td><pre>        <span class="token comment"># reshape</span></pre></td></tr><tr><td data-num="44"></td><td><pre>        x <span class="token operator">=</span> x<span class="token punctuation">.</span>view<span class="token punctuation">(</span>batchsz<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="45"></td><td><pre></pre></td></tr><tr><td data-num="46"></td><td><pre>        <span class="token keyword">return</span> x<span class="token punctuation">,</span> <span class="token boolean">None</span></pre></td></tr></table></figure><h3 id="variational-autoencoders-代码"><a class="anchor" href="#variational-autoencoders-代码">#</a> Variational AutoEncoders 代码</h3><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">import</span>  torch</pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token keyword">from</span>    torch <span class="token keyword">import</span> nn</pre></td></tr><tr><td data-num="3"></td><td><pre></pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token keyword">class</span> <span class="token class-name">VAE</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="5"></td><td><pre></pre></td></tr><tr><td data-num="6"></td><td><pre>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="7"></td><td><pre>        <span class="token builtin">super</span><span class="token punctuation">(</span>VAE<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="8"></td><td><pre>        <span class="token comment"># [b, 784] => [b, 20]</span></pre></td></tr><tr><td data-num="9"></td><td><pre>        <span class="token comment"># u: [b, 10]</span></pre></td></tr><tr><td data-num="10"></td><td><pre>        <span class="token comment"># sigma: [b, 10]</span></pre></td></tr><tr><td data-num="11"></td><td><pre>        self<span class="token punctuation">.</span>encoder <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span></pre></td></tr><tr><td data-num="12"></td><td><pre>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">784</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">)</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="13"></td><td><pre>            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="14"></td><td><pre>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">)</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="15"></td><td><pre>            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="16"></td><td><pre>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">)</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="17"></td><td><pre>            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="18"></td><td><pre>        <span class="token punctuation">)</span></pre></td></tr><tr><td data-num="19"></td><td><pre>        <span class="token comment"># [b, 20] => [b, 784]</span></pre></td></tr><tr><td data-num="20"></td><td><pre>        self<span class="token punctuation">.</span>decoder <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span></pre></td></tr><tr><td data-num="21"></td><td><pre>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">)</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="22"></td><td><pre>            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="23"></td><td><pre>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">)</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="24"></td><td><pre>            nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="25"></td><td><pre>            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">784</span><span class="token punctuation">)</span><span class="token punctuation">,</span></pre></td></tr><tr><td data-num="26"></td><td><pre>            nn<span class="token punctuation">.</span>Sigmoid<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="27"></td><td><pre>        <span class="token punctuation">)</span></pre></td></tr><tr><td data-num="28"></td><td><pre></pre></td></tr><tr><td data-num="29"></td><td><pre>        self<span class="token punctuation">.</span>criteon <span class="token operator">=</span> nn<span class="token punctuation">.</span>MSELoss<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="30"></td><td><pre></pre></td></tr><tr><td data-num="31"></td><td><pre>    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="32"></td><td><pre>        <span class="token triple-quoted-string string">"""</span></pre></td></tr><tr><td data-num="33"></td><td><pre></pre></td></tr><tr><td data-num="34"></td><td><pre>        :param x: [b, 1, 28, 28]</pre></td></tr><tr><td data-num="35"></td><td><pre>        :return:</pre></td></tr><tr><td data-num="36"></td><td><pre>        """</pre></td></tr><tr><td data-num="37"></td><td><pre>        batchsz <span class="token operator">=</span> x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="38"></td><td><pre>        <span class="token comment"># flatten</span></pre></td></tr><tr><td data-num="39"></td><td><pre>        x <span class="token operator">=</span> x<span class="token punctuation">.</span>view<span class="token punctuation">(</span>batchsz<span class="token punctuation">,</span> <span class="token number">784</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="40"></td><td><pre>        <span class="token comment"># encoder</span></pre></td></tr><tr><td data-num="41"></td><td><pre>        <span class="token comment"># [b, 20], including mean and sigma</span></pre></td></tr><tr><td data-num="42"></td><td><pre>        h_ <span class="token operator">=</span> self<span class="token punctuation">.</span>encoder<span class="token punctuation">(</span>x<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="43"></td><td><pre>        <span class="token comment"># [b, 20] => [b, 10] and [b, 10]</span></pre></td></tr><tr><td data-num="44"></td><td><pre>        mu<span class="token punctuation">,</span> sigma <span class="token operator">=</span> h_<span class="token punctuation">.</span>chunk<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="45"></td><td><pre>        <span class="token comment"># reparametrize trick, epison~N(0, 1)</span></pre></td></tr><tr><td data-num="46"></td><td><pre>        h <span class="token operator">=</span> mu <span class="token operator">+</span> sigma <span class="token operator">*</span> torch<span class="token punctuation">.</span>randn_like<span class="token punctuation">(</span>sigma<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="47"></td><td><pre></pre></td></tr><tr><td data-num="48"></td><td><pre>        <span class="token comment"># decoder</span></pre></td></tr><tr><td data-num="49"></td><td><pre>        x_hat <span class="token operator">=</span> self<span class="token punctuation">.</span>decoder<span class="token punctuation">(</span>h<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="50"></td><td><pre>        <span class="token comment"># reshape</span></pre></td></tr><tr><td data-num="51"></td><td><pre>        x_hat <span class="token operator">=</span> x_hat<span class="token punctuation">.</span>view<span class="token punctuation">(</span>batchsz<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="52"></td><td><pre></pre></td></tr><tr><td data-num="53"></td><td><pre>        kld <span class="token operator">=</span> <span class="token number">0.5</span> <span class="token operator">*</span> torch<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span></pre></td></tr><tr><td data-num="54"></td><td><pre>            torch<span class="token punctuation">.</span><span class="token builtin">pow</span><span class="token punctuation">(</span>mu<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span> <span class="token operator">+</span></pre></td></tr><tr><td data-num="55"></td><td><pre>            torch<span class="token punctuation">.</span><span class="token builtin">pow</span><span class="token punctuation">(</span>sigma<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span> <span class="token operator">-</span></pre></td></tr><tr><td data-num="56"></td><td><pre>            torch<span class="token punctuation">.</span>log<span class="token punctuation">(</span><span class="token number">1e-8</span> <span class="token operator">+</span> torch<span class="token punctuation">.</span><span class="token builtin">pow</span><span class="token punctuation">(</span>sigma<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token number">1</span></pre></td></tr><tr><td data-num="57"></td><td><pre>        <span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token punctuation">(</span>batchsz<span class="token operator">*</span><span class="token number">28</span><span class="token operator">*</span><span class="token number">28</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="58"></td><td><pre></pre></td></tr><tr><td data-num="59"></td><td><pre>        <span class="token keyword">return</span> x_hat<span class="token punctuation">,</span> kld</pre></td></tr></table></figure><h3 id="main-代码"><a class="anchor" href="#main-代码">#</a> Main 代码</h3><figure class="highlight python"><figcaption data-lang="python"></figcaption><table><tr><td data-num="1"></td><td><pre><span class="token keyword">import</span>  torch</pre></td></tr><tr><td data-num="2"></td><td><pre><span class="token keyword">from</span>    torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> DataLoader</pre></td></tr><tr><td data-num="3"></td><td><pre><span class="token keyword">from</span>    torch <span class="token keyword">import</span> nn<span class="token punctuation">,</span> optim</pre></td></tr><tr><td data-num="4"></td><td><pre><span class="token keyword">from</span>    torchvision <span class="token keyword">import</span> transforms<span class="token punctuation">,</span> datasets</pre></td></tr><tr><td data-num="5"></td><td><pre></pre></td></tr><tr><td data-num="6"></td><td><pre><span class="token keyword">from</span>    ae <span class="token keyword">import</span> AE</pre></td></tr><tr><td data-num="7"></td><td><pre><span class="token keyword">from</span>    vae <span class="token keyword">import</span> VAE</pre></td></tr><tr><td data-num="8"></td><td><pre></pre></td></tr><tr><td data-num="9"></td><td><pre><span class="token keyword">import</span>  visdom</pre></td></tr><tr><td data-num="10"></td><td><pre></pre></td></tr><tr><td data-num="11"></td><td><pre><span class="token keyword">def</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="12"></td><td><pre>    mnist_train <span class="token operator">=</span> datasets<span class="token punctuation">.</span>MNIST<span class="token punctuation">(</span><span class="token string">'mnist'</span><span class="token punctuation">,</span> <span class="token boolean">True</span><span class="token punctuation">,</span> transform<span class="token operator">=</span>transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span><span class="token punctuation">[</span></pre></td></tr><tr><td data-num="13"></td><td><pre>        transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="14"></td><td><pre>    <span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="15"></td><td><pre>    mnist_train <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>mnist_train<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="16"></td><td><pre></pre></td></tr><tr><td data-num="17"></td><td><pre></pre></td></tr><tr><td data-num="18"></td><td><pre>    mnist_test <span class="token operator">=</span> datasets<span class="token punctuation">.</span>MNIST<span class="token punctuation">(</span><span class="token string">'mnist'</span><span class="token punctuation">,</span> <span class="token boolean">False</span><span class="token punctuation">,</span> transform<span class="token operator">=</span>transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span><span class="token punctuation">[</span></pre></td></tr><tr><td data-num="19"></td><td><pre>        transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="20"></td><td><pre>    <span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="21"></td><td><pre>    mnist_test <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>mnist_test<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">32</span><span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="22"></td><td><pre></pre></td></tr><tr><td data-num="23"></td><td><pre>    x<span class="token punctuation">,</span> _ <span class="token operator">=</span> <span class="token builtin">iter</span><span class="token punctuation">(</span>mnist_train<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">next</span><span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="24"></td><td><pre>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'x:'</span><span class="token punctuation">,</span> x<span class="token punctuation">.</span>shape<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="25"></td><td><pre></pre></td></tr><tr><td data-num="26"></td><td><pre>    device <span class="token operator">=</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">'cuda'</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="27"></td><td><pre>    <span class="token comment"># model = AE().to(device)</span></pre></td></tr><tr><td data-num="28"></td><td><pre>    model <span class="token operator">=</span> VAE<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="29"></td><td><pre>    criteon <span class="token operator">=</span> nn<span class="token punctuation">.</span>MSELoss<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="30"></td><td><pre>    optimizer <span class="token operator">=</span> optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">1e-3</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="31"></td><td><pre>    <span class="token keyword">print</span><span class="token punctuation">(</span>model<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="32"></td><td><pre></pre></td></tr><tr><td data-num="33"></td><td><pre>    viz <span class="token operator">=</span> visdom<span class="token punctuation">.</span>Visdom<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="34"></td><td><pre></pre></td></tr><tr><td data-num="35"></td><td><pre>    <span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">1000</span><span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="36"></td><td><pre></pre></td></tr><tr><td data-num="37"></td><td><pre>        <span class="token keyword">for</span> batchidx<span class="token punctuation">,</span> <span class="token punctuation">(</span>x<span class="token punctuation">,</span> _<span class="token punctuation">)</span> <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>mnist_train<span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="38"></td><td><pre>            <span class="token comment"># [b, 1, 28, 28]</span></pre></td></tr><tr><td data-num="39"></td><td><pre>            x <span class="token operator">=</span> x<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="40"></td><td><pre></pre></td></tr><tr><td data-num="41"></td><td><pre>            x_hat<span class="token punctuation">,</span> kld <span class="token operator">=</span> model<span class="token punctuation">(</span>x<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="42"></td><td><pre>            loss <span class="token operator">=</span> criteon<span class="token punctuation">(</span>x_hat<span class="token punctuation">,</span> x<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="43"></td><td><pre></pre></td></tr><tr><td data-num="44"></td><td><pre>            <span class="token keyword">if</span> kld <span class="token keyword">is</span> <span class="token keyword">not</span> <span class="token boolean">None</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="45"></td><td><pre>                elbo <span class="token operator">=</span> <span class="token operator">-</span> loss <span class="token operator">-</span> <span class="token number">1.0</span> <span class="token operator">*</span> kld</pre></td></tr><tr><td data-num="46"></td><td><pre>                loss <span class="token operator">=</span> <span class="token operator">-</span> elbo</pre></td></tr><tr><td data-num="47"></td><td><pre></pre></td></tr><tr><td data-num="48"></td><td><pre>            <span class="token comment"># backprop</span></pre></td></tr><tr><td data-num="49"></td><td><pre>            optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="50"></td><td><pre>            loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="51"></td><td><pre>            optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="52"></td><td><pre></pre></td></tr><tr><td data-num="53"></td><td><pre>        <span class="token keyword">print</span><span class="token punctuation">(</span>epoch<span class="token punctuation">,</span> <span class="token string">'loss:'</span><span class="token punctuation">,</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">'kld:'</span><span class="token punctuation">,</span> kld<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="54"></td><td><pre></pre></td></tr><tr><td data-num="55"></td><td><pre>        x<span class="token punctuation">,</span> _ <span class="token operator">=</span> <span class="token builtin">iter</span><span class="token punctuation">(</span>mnist_test<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">next</span><span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="56"></td><td><pre>        x <span class="token operator">=</span> x<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="57"></td><td><pre>        <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="58"></td><td><pre>            x_hat<span class="token punctuation">,</span> kld <span class="token operator">=</span> model<span class="token punctuation">(</span>x<span class="token punctuation">)</span></pre></td></tr><tr><td data-num="59"></td><td><pre>        viz<span class="token punctuation">.</span>images<span class="token punctuation">(</span>x<span class="token punctuation">,</span> nrow<span class="token operator">=</span><span class="token number">8</span><span class="token punctuation">,</span> win<span class="token operator">=</span><span class="token string">'x'</span><span class="token punctuation">,</span> opts<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span>title<span class="token operator">=</span><span class="token string">'x'</span><span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="60"></td><td><pre>        viz<span class="token punctuation">.</span>images<span class="token punctuation">(</span>x_hat<span class="token punctuation">,</span> nrow<span class="token operator">=</span><span class="token number">8</span><span class="token punctuation">,</span> win<span class="token operator">=</span><span class="token string">'x_hat'</span><span class="token punctuation">,</span> opts<span class="token operator">=</span><span class="token builtin">dict</span><span class="token punctuation">(</span>title<span class="token operator">=</span><span class="token string">'x_hat'</span><span class="token punctuation">)</span><span class="token punctuation">)</span></pre></td></tr><tr><td data-num="61"></td><td><pre></pre></td></tr><tr><td data-num="62"></td><td><pre><span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span></pre></td></tr><tr><td data-num="63"></td><td><pre>    main<span class="token punctuation">(</span><span class="token punctuation">)</span></pre></td></tr></table></figure><div class="tags"><a href="/tags/PyTorch/" rel="tag"><i class="ic i-tag"></i> PyTorch</a></div></div><footer><div class="meta"><span class="item"><span class="icon"><i class="ic i-calendar-check"></i> </span><span class="text">更新于</span> <time title="修改时间：2024-08-31 01:57:41" itemprop="dateModified" datetime="2024-08-31T01:57:41+08:00">2024-08-31</time> </span><span id="artificial-intelligence/pytorch/20230801/" class="item leancloud_visitors" data-flag-title="PyTorch学习笔记（11）自编码器Auto-Encoders" title="阅读次数"><span class="icon"><i class="ic i-eye"></i> </span><span class="text">阅读次数</span> <span class="leancloud-visitors-count"></span> <span class="text">次</span></span></div><div class="reward"><button><i class="ic i-heartbeat"></i> 赞赏</button><p>请我喝[茶]~(￣▽￣)~*</p><div id="qr"><div><img data-src="/images/wechatpay.png" alt="宇凌喵 微信支付"><p>微信支付</p></div><div><img data-src="/images/alipay.png" alt="宇凌喵 支付宝"><p>支付宝</p></div></div></div><div id="copyright"><ul><li class="author"><strong>本文作者： </strong>宇凌喵 <i class="ic i-at"><em>@</em></i>学无止境</li><li class="link"><strong>本文链接：</strong> <a href="https://blog.aayu.today/artificial-intelligence/pytorch/20230801/" title="PyTorch学习笔记（11）自编码器Auto-Encoders">https://blog.aayu.today/artificial-intelligence/pytorch/20230801/</a></li><li class="license"><strong>版权声明： </strong>本站所有文章除特别声明外，均采用 <span class="exturl" data-url="aHR0cHM6Ly9jcmVhdGl2ZWNvbW1vbnMub3JnL2xpY2Vuc2VzL2J5LW5jLXNhLzQuMC9kZWVkLnpo"><i class="ic i-creative-commons"><em>(CC)</em></i>BY-NC-SA</span> 许可协议。转载请注明出处！</li></ul></div></footer></article></div><div class="post-nav"><div class="item left"><a href="/artificial-intelligence/pytorch/20230731-2/" itemprop="url" rel="prev" data-background-image="https:&#x2F;&#x2F;image.aayu.today&#x2F;uploads&#x2F;2022&#x2F;12&#x2F;28&#x2F;6833939bly1gipevgoki5j20zk0m84qp.jpg" title="PyTorch学习笔记（10）长短期神经网络LSTM"><span class="type">上一篇</span> <span class="category"><i class="ic i-flag"></i> 机器学习修炼之PyTorch</span><h3>PyTorch学习笔记（10）长短期神经网络LSTM</h3></a></div><div class="item right"><a href="/artificial-intelligence/pytorch/20230802/" itemprop="url" rel="next" data-background-image="https:&#x2F;&#x2F;image.aayu.today&#x2F;uploads&#x2F;2023&#x2F;09&#x2F;04&#x2F;202309042336361.png" title="PyTorch学习笔记（12）对抗生成网络GAN"><span class="type">下一篇</span> <span class="category"><i class="ic i-flag"></i> 机器学习修炼之PyTorch</span><h3>PyTorch学习笔记（12）对抗生成网络GAN</h3></a></div></div><div class="wrap" id="comments"></div></div><div id="sidebar"><div class="inner"><div class="panels"><div class="inner"><div class="contents panel pjax" data-title="文章目录"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#pca-vs-auto-encoders"><span class="toc-number">1.</span> <span class="toc-text">PCA V.S. Auto-Encoders</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#auto-encoders-%E5%8F%98%E7%A7%8D"><span class="toc-number">2.</span> <span class="toc-text">Auto-Encoders 变种</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#denoising-autoencoders"><span class="toc-number">2.1.</span> <span class="toc-text">Denoising AutoEncoders</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#dropout-autoencoders"><span class="toc-number">2.2.</span> <span class="toc-text">Dropout AutoEncoders</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#adversarial-autoencoders"><span class="toc-number">2.3.</span> <span class="toc-text">Adversarial AutoEncoders</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#variational-autoencoders"><span class="toc-number">3.</span> <span class="toc-text">Variational AutoEncoders</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#kl-%E6%95%A3%E5%BA%A6%E7%9A%84%E8%AE%A1%E7%AE%97"><span class="toc-number">3.1.</span> <span class="toc-text">KL 散度的计算</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#reparameterization-trick"><span class="toc-number">3.2.</span> <span class="toc-text">Reparameterization trick</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%BA%94%E7%94%A8"><span class="toc-number">3.3.</span> <span class="toc-text">应用</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%A3%E7%A0%81%E5%AE%9E%E6%88%98"><span class="toc-number">4.</span> <span class="toc-text">代码实战</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#auto-encoders-%E4%BB%A3%E7%A0%81"><span class="toc-number">4.1.</span> <span class="toc-text">Auto-Encoders 代码</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#variational-autoencoders-%E4%BB%A3%E7%A0%81"><span class="toc-number">4.2.</span> <span class="toc-text">Variational AutoEncoders 代码</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#main-%E4%BB%A3%E7%A0%81"><span class="toc-number">4.3.</span> <span class="toc-text">Main 代码</span></a></li></ol></li></ol></div><div class="related panel pjax" data-title="系列文章"><ul><li><a href="/artificial-intelligence/pytorch/20200602/" rel="bookmark" title="Pytorch-Pytorch安装">Pytorch-Pytorch安装</a></li><li><a href="/artificial-intelligence/pytorch/20200606/" rel="bookmark" title="Pytorch-制作自己的多标签数据集">Pytorch-制作自己的多标签数据集</a></li><li><a href="/artificial-intelligence/pytorch/20200607-1/" rel="bookmark" title="Pytorch-Dropout用法">Pytorch-Dropout用法</a></li><li><a href="/artificial-intelligence/pytorch/20200607-2/" rel="bookmark" title="Pytorch-多输出回归任务实战">Pytorch-多输出回归任务实战</a></li><li><a href="/artificial-intelligence/pytorch/20200610/" rel="bookmark" title="Pytorch-多输出回归任务实战（二）">Pytorch-多输出回归任务实战（二）</a></li><li><a href="/artificial-intelligence/pytorch/20210311/" rel="bookmark" title="Pytorch-常用的交叉熵损失函数CrossEntropyLoss详解">Pytorch-常用的交叉熵损失函数CrossEntropyLoss详解</a></li><li><a href="/artificial-intelligence/pytorch/20210312/" rel="bookmark" title="Pytorch-nn.Softmax函数详解">Pytorch-nn.Softmax函数详解</a></li><li><a href="/artificial-intelligence/pytorch/20210412-1/" rel="bookmark" title="20210412-原理-梯度弥散和梯度爆炸">20210412-原理-梯度弥散和梯度爆炸</a></li><li><a href="/artificial-intelligence/pytorch/20210412-2/" rel="bookmark" title="原理-详解sigmoid与softmax，多分类与多标签分类">原理-详解sigmoid与softmax，多分类与多标签分类</a></li><li><a href="/artificial-intelligence/pytorch/20230716/" rel="bookmark" title="PyTorch学习笔记（1）">PyTorch学习笔记（1）</a></li><li><a href="/artificial-intelligence/pytorch/20230717/" rel="bookmark" title="PyTorch学习笔记（2）">PyTorch学习笔记（2）</a></li><li><a href="/artificial-intelligence/pytorch/20230717-2/" rel="bookmark" title="PyTorch学习笔记（3）随机梯度下降">PyTorch学习笔记（3）随机梯度下降</a></li><li><a href="/artificial-intelligence/pytorch/20230718/" rel="bookmark" title="PyTorch学习笔记（4）神经网络与全连接层">PyTorch学习笔记（4）神经网络与全连接层</a></li><li><a href="/artificial-intelligence/pytorch/20230718-2/" rel="bookmark" title="PyTorch学习笔记（5）过拟合问题">PyTorch学习笔记（5）过拟合问题</a></li><li><a href="/artificial-intelligence/pytorch/20230719/" rel="bookmark" title="PyTorch学习笔记（6）卷积神经网络">PyTorch学习笔记（6）卷积神经网络</a></li><li><a href="/artificial-intelligence/pytorch/20230719-2/" rel="bookmark" title="PyTorch学习笔记（7）ResNet实战">PyTorch学习笔记（7）ResNet实战</a></li><li><a href="/artificial-intelligence/pytorch/20230719-3/" rel="bookmark" title="PyTorch学习笔记（8）迁移学习实战">PyTorch学习笔记（8）迁移学习实战</a></li><li><a href="/artificial-intelligence/pytorch/20230731/" rel="bookmark" title="PyTorch学习笔记（9）循环神经网络RNN">PyTorch学习笔记（9）循环神经网络RNN</a></li><li><a href="/artificial-intelligence/pytorch/20230731-2/" rel="bookmark" title="PyTorch学习笔记（10）长短期神经网络LSTM">PyTorch学习笔记（10）长短期神经网络LSTM</a></li><li class="active"><a href="/artificial-intelligence/pytorch/20230801/" rel="bookmark" title="PyTorch学习笔记（11）自编码器Auto-Encoders">PyTorch学习笔记（11）自编码器Auto-Encoders</a></li><li><a href="/artificial-intelligence/pytorch/20230802/" rel="bookmark" title="PyTorch学习笔记（12）对抗生成网络GAN">PyTorch学习笔记（12）对抗生成网络GAN</a></li></ul></div><div class="overview panel" data-title="站点概览"><div class="author" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="image" itemprop="image" alt="宇凌喵" data-src="/images/avatar.jpg"><p class="name" itemprop="name">宇凌喵</p><div class="description" itemprop="description">真理和热爱是吾永生的追求</div></div><nav class="state"><div class="item posts"><a href="/archives/"><span class="count">388</span> <span class="name">文章</span></a></div><div class="item categories"><a href="/categories/"><span class="count">101</span> <span class="name">分类</span></a></div><div class="item tags"><a href="/tags/"><span class="count">135</span> <span class="name">标签</span></a></div></nav><div class="social"><span class="exturl item github" data-url="aHR0cHM6Ly9naXRodWIuY29tL3lsc2lzbG92ZQ==" title="https:&#x2F;&#x2F;github.com&#x2F;ylsislove"><i class="ic i-github"></i></span> <span class="exturl item weibo" data-url="aHR0cHM6Ly93ZWliby5jb20veW91cm5hbWU=" title="https:&#x2F;&#x2F;weibo.com&#x2F;yourname"><i class="ic i-weibo"></i></span> <span class="exturl item email" data-url="bWFpbHRvOjkxNjQ5MTAxM0BxcS5jb20=" title="mailto:916491013@qq.com"><i class="ic i-envelope"></i></span></div><ul class="menu"><li class="item"><a href="/" rel="section"><i class="ic i-home"></i>首页</a></li><li class="item"><a href="/about/" rel="section"><i class="ic i-user"></i>关于</a></li><li class="item dropdown"><a href="javascript:void(0);"><i class="ic i-feather"></i>文章</a><ul class="submenu"><li class="item"><a href="/archives/" rel="section"><i class="ic i-list-alt"></i>归档</a></li><li class="item"><a href="/categories/" rel="section"><i class="ic i-th"></i>分类</a></li><li class="item"><a href="/tags/" rel="section"><i class="ic i-tags"></i>标签</a></li></ul></li><li class="item dropdown"><a href="javascript:void(0);"><i class="ic i-magic"></i>链环</a><ul class="submenu"><li class="item"><a href="/friends/" rel="section"><i class="ic i-heart"></i>友達</a></li><li class="item"><a href="/webstack/" rel="section"><i class="ic i-star"></i>网址</a></li></ul></li><li class="item"><span class="exturl" data-url="aHR0cHM6Ly9mb3JldmVyYmxvZy5jbi9nby5odG1s"><i class="ic i-paper-plane"></i>虫洞</span></li></ul></div></div></div><ul id="quick"><li class="prev pjax"><a href="/artificial-intelligence/pytorch/20230731-2/" rel="prev" title="上一篇"><i class="ic i-chevron-left"></i></a></li><li class="up"><i class="ic i-arrow-up"></i></li><li class="down"><i class="ic i-arrow-down"></i></li><li class="next pjax"><a href="/artificial-intelligence/pytorch/20230802/" rel="next" title="下一篇"><i class="ic i-chevron-right"></i></a></li><li class="percent"></li></ul></div></div><div class="dimmer"></div></div></main><footer id="footer"><div class="inner"><div class="widgets"><div class="rpost pjax"><h2>随机文章</h2><ul><li class="item"><div class="breadcrumb"><a href="/categories/skill/" title="分类于 不看会后悔的实用技巧分享">不看会后悔的实用技巧分享</a> <i class="ic i-angle-right"></i> <a href="/categories/skill/miscellaneous/" title="分类于 杂七杂八">杂七杂八</a></div><span><a href="/skill/miscellaneous/20230702/" title="机械臂学习笔记">机械臂学习笔记</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/english/" title="分类于 英语学习之路">英语学习之路</a> <i class="ic i-angle-right"></i> <a href="/categories/english/ielts/" title="分类于 雅思备战">雅思备战</a></div><span><a href="/english/ielts/20200629/" title="雅思写作-大作文评分标准">雅思写作-大作文评分标准</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/front-end/" title="分类于 前端系列">前端系列</a> <i class="ic i-angle-right"></i> <a href="/categories/front-end/es567/" title="分类于 ECMAScript">ECMAScript</a></div><span><a href="/front-end/es567/20200526-1/" title="前端-ES5知识点总结">前端-ES5知识点总结</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/artificial-intelligence/" title="分类于 人工智能">人工智能</a> <i class="ic i-angle-right"></i> <a href="/categories/artificial-intelligence/machine-learning/" title="分类于 机器学习">机器学习</a> <i class="ic i-angle-right"></i> <a href="/categories/artificial-intelligence/machine-learning/hmm/" title="分类于 隐马尔可夫模型">隐马尔可夫模型</a></div><span><a href="/artificial-intelligence/machine-learning/hmm/20221207/" title="隐马尔科夫模型">隐马尔科夫模型</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/english/" title="分类于 英语学习之路">英语学习之路</a> <i class="ic i-angle-right"></i> <a href="/categories/english/ielts/" title="分类于 雅思备战">雅思备战</a></div><span><a href="/english/ielts/20200714/" title="雅思写作-18个基本句型（一）">雅思写作-18个基本句型（一）</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/back-end/" title="分类于 后端系列">后端系列</a> <i class="ic i-angle-right"></i> <a href="/categories/back-end/golang/" title="分类于 Golang">Golang</a></div><span><a href="/back-end/golang/20210313-1/" title="golang-理解Golang中defer的使用">golang-理解Golang中defer的使用</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/algorithm/" title="分类于 数据结构与算法">数据结构与算法</a> <i class="ic i-angle-right"></i> <a href="/categories/algorithm/dp/" title="分类于 动态规划">动态规划</a></div><span><a href="/algorithm/dp/20220727/" title="动态规划：打家劫舍 II">动态规划：打家劫舍 II</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/front-end/" title="分类于 前端系列">前端系列</a> <i class="ic i-angle-right"></i> <a href="/categories/front-end/webpack/" title="分类于 Webpack">Webpack</a></div><span><a href="/front-end/webpack/20200628-3/" title="前端-webpack开发环境基本配置">前端-webpack开发环境基本配置</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/hardware/" title="分类于 硬件修炼手册">硬件修炼手册</a> <i class="ic i-angle-right"></i> <a href="/categories/hardware/raspberry-pi/" title="分类于 树莓派">树莓派</a></div><span><a href="/hardware/raspberry-pi/20210914-2/" title="树莓派-PS2操作杆实验">树莓派-PS2操作杆实验</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/skill/" title="分类于 不看会后悔的实用技巧分享">不看会后悔的实用技巧分享</a> <i class="ic i-angle-right"></i> <a href="/categories/skill/blog/" title="分类于 个人博客">个人博客</a></div><span><a href="/skill/blog/20210605/" title="用 Hexo 和 GitHub Pages 搭建博客">用 Hexo 和 GitHub Pages 搭建博客</a></span></li></ul></div><div><h2>最新评论</h2><ul class="leancloud-recent-comment"></ul></div></div><div class="status"><div class="copyright">&copy; 2020 – <span itemprop="copyrightYear">2024</span> <span class="with-love"><i class="ic i-sakura rotate"></i> </span><span class="author" itemprop="copyrightHolder">宇凌喵 @ Aayu Yain</span></div><div class="count"><span class="post-meta-item-icon"><i class="ic i-chart-area"></i> </span><span title="站点总字数">829k 字</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="ic i-coffee"></i> </span><span title="站点阅读时长">12:34</span> <span class="beian"><i class="ic i-beian1"></i> </span><span>晋ICP备19006357号-4</span></div><div class="powered-by">基于 <span class="exturl" data-url="aHR0cHM6Ly9oZXhvLmlv">Hexo</span> & Theme.<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2FtZWhpbWUvaGV4by10aGVtZS1zaG9rYQ==">Shoka</span></div></div></div></footer></div><script data-config type="text/javascript">var LOCAL={path:"artificial-intelligence/pytorch/20230801/",favicon:{show:"（●´3｀●）やれやれだぜ",hide:"(´Д｀)大変だ！"},search:{placeholder:"文章搜索",empty:"关于 「 ${query} 」，什么也没搜到",stats:"${time} ms 内找到 ${hits} 条结果"},valine:!0,copy_tex:!0,katex:!0,fancybox:!0,copyright:'复制成功，转载请遵守 <i class="ic i-creative-commons"></i>BY-NC-SA 协议。',ignores:[function(e){return e.includes("#")},function(e){return new RegExp(LOCAL.path+"$").test(e)}]}</script><script src="assets/polyfill.js"></script><script src="/assets/quicklink.umd.js"></script><script src="/js/app.js?v=0.2.5"></script></body></html><!-- rebuild by hrmmi -->