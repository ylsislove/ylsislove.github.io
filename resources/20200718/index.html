<!-- build time:Sat Mar 12 2022 11:29:41 GMT+0800 (GMT+08:00) --><!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#FFF"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png"><link rel="icon" type="image/ico" sizes="32x32" href="/images/favicon.ico"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="alternate" type="application/rss+xml" title="学无止境" href="https://blog.aayu.today/rss.xml"><link rel="alternate" type="application/atom+xml" title="学无止境" href="https://blog.aayu.today/atom.xml"><link rel="alternate" type="application/json" title="学无止境" href="https://blog.aayu.today/feed.json"><link rel="stylesheet" href="//fonts.googleapis.com/css?family=Mulish:300,300italic,400,400italic,700,700italic%7CFredericka%20the%20Great:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20JP:300,300italic,400,400italic,700,700italic%7CNoto%20Serif%20SC:300,300italic,400,400italic,700,700italic%7CInconsolata:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext"><link rel="stylesheet" href="/css/app.css?v=0.2.5"><meta name="keywords" content="资源"><link rel="canonical" href="https://blog.aayu.today/resources/20200718/"><title>机器学习必读TOP100论文清单 - 资源 | Aayu Yain = 学无止境 = 阿宇的可爱博客</title><meta name="generator" content="Hexo 5.4.0"></head><body itemscope itemtype="http://schema.org/WebPage"><div id="loading"><div class="cat"><div class="body"></div><div class="head"><div class="face"></div></div><div class="foot"><div class="tummy-end"></div><div class="bottom"></div><div class="legs left"></div><div class="legs right"></div></div><div class="paw"><div class="hands left"></div><div class="hands right"></div></div></div></div><div id="container"><header id="header" itemscope itemtype="http://schema.org/WPHeader"><div class="inner"><div id="brand"><div class="pjax"><h1 itemprop="name headline">机器学习必读TOP100论文清单</h1><div class="meta"><span class="item" title="创建时间：2020-07-18 00:00:00"><span class="icon"><i class="ic i-calendar"></i> </span><span class="text">发表于</span> <time itemprop="dateCreated datePublished" datetime="2020-07-18T00:00:00+08:00">2020-07-18</time> </span><span class="item" title="本文字数"><span class="icon"><i class="ic i-pen"></i> </span><span class="text">本文字数</span> <span>5.4k</span> <span class="text">字</span> </span><span class="item" title="阅读时长"><span class="icon"><i class="ic i-clock"></i> </span><span class="text">阅读时长</span> <span>5 分钟</span></span></div></div></div><nav id="nav"><div class="inner"><div class="toggle"><div class="lines" aria-label="切换导航栏"><span class="line"></span> <span class="line"></span> <span class="line"></span></div></div><ul class="menu"><li class="item title"><a href="/" rel="start">Aayu Yain</a></li></ul><ul class="right"><li class="item theme"><i class="ic i-sun"></i></li><li class="item search"><i class="ic i-search"></i></li></ul></div></nav></div><div id="imgs" class="pjax"><ul><li class="item" data-background-image="https://tva4.sinaimg.cn/large/6833939bly1giclimtf7dj20zk0m8qav.jpg"></li><li class="item" data-background-image="https://tva4.sinaimg.cn/large/6833939bly1gipeun65urj20zk0m81ii.jpg"></li><li class="item" data-background-image="https://tva4.sinaimg.cn/large/6833939bly1giclh0m9pdj20zk0m8hdt.jpg"></li><li class="item" data-background-image="https://tva4.sinaimg.cn/large/6833939bly1giclx6phq6j20zk0m8e36.jpg"></li><li class="item" data-background-image="http://image.aayu.today/2022/01/18/54c00f9448c91.png"></li><li class="item" data-background-image="https://tva4.sinaimg.cn/large/6833939bly1giciukx8a7j20zk0m8aio.jpg"></li></ul></div></header><div id="waves"><svg class="waves" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 24 150 28" preserveAspectRatio="none" shape-rendering="auto"><defs><path id="gentle-wave" d="M-160 44c30 0 58-18 88-18s 58 18 88 18 58-18 88-18 58 18 88 18 v44h-352z"/></defs><g class="parallax"><use xlink:href="#gentle-wave" x="48" y="0"/><use xlink:href="#gentle-wave" x="48" y="3"/><use xlink:href="#gentle-wave" x="48" y="5"/><use xlink:href="#gentle-wave" x="48" y="7"/></g></svg></div><main><div class="inner"><div id="main" class="pjax"><div class="article wrap"><div class="breadcrumb" itemscope itemtype="https://schema.org/BreadcrumbList"><i class="ic i-home"></i> <span><a href="/">首页</a></span><i class="ic i-angle-right"></i> <span class="current" itemprop="itemListElement" itemscope itemtype="https://schema.org/ListItem"><a href="/categories/resources/" itemprop="item" rel="index" title="分类于 资源"><span itemprop="name">资源</span></a><meta itemprop="position" content="1"></span></div><article itemscope itemtype="http://schema.org/Article" class="post block" lang="zh-CN"><link itemprop="mainEntityOfPage" href="https://blog.aayu.today/resources/20200718/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/avatar.jpg"><meta itemprop="name" content="宇凌喵"><meta itemprop="description" content="阿宇的可爱博客, 真理和热爱是吾永生的追求"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="学无止境"></span><div class="body md" itemprop="articleBody"><h2 id="前言"><a class="anchor" href="#前言">#</a> 前言</h2><p>想要入门机器学习，奈何领域的新论文太多，不知道该看哪一篇？</p><p>自 2017 年以来，超越 SOTA 的方法天天有，但往往针对性非常强，不一定是颠覆机器学习圈的重要成果。</p><p>又回到了熟悉的话题：要想入行，还得看高引用经典论文。</p><p>这里整合了 2012 年到 2016 年的高引 TOP 100 论文，引用量要求随着年份递减而递增，Hinton、Bengio、何恺明等大牛的论文都在其中，一起来看看吧。</p><p>这个仓库也好久没更新了，希望自己能在学习的过程中渐渐形成自己的论文仓库，永不断更！</p><h2 id="清单列表"><a class="anchor" href="#清单列表">#</a> 清单列表</h2><h3 id="理解-泛化-迁移学习"><a class="anchor" href="#理解-泛化-迁移学习">#</a> 理解、泛化、迁移学习</h3><ol><li><p>Distilling the knowledge in a neural network (2015), G. Hinton et al.</p><blockquote><p><span class="exturl" data-url="aHR0cDovL2FyeGl2Lm9yZy9wZGYvMTUwMy4wMjUzMQ==">http://arxiv.org/pdf/1503.02531</span></p></blockquote><p>这篇介绍了 Hinton 大神在 15 年做的一个黑科技技术，Hinton 在一些报告中称之为 Dark Knowledge，技术上一般叫做知识蒸馏（Knowledge Distillation）。这篇论文的核心思想是通过迁移知识，从而以训练好的大模型得到更加适合推理的小模型。</p></li><li><p>Deep neural networks are easily fooled: High confidence predictions for unrecognizable images (2015), A. Nguyen et al.</p><blockquote><p><span class="exturl" data-url="aHR0cDovL2FyeGl2Lm9yZy9wZGYvMTQxMi4xODk3">http://arxiv.org/pdf/1412.1897</span></p></blockquote><p>研究结果揭示了人的视觉和目前 DNNs 的差异。具体来说，卷积神经网络在 ImageNet 或 MNIST 数据集上训练都表现良好，但发现通过进化算法或梯度上升处理的图片，DNNs 以很高的置信度贴以标签属于某个数据集类（其实不属于这个数据集类）。</p></li><li><p>How transferable are features in deep neural networks? (2014), J. Yosinski et al.</p><blockquote><p><span class="exturl" data-url="aHR0cDovL3BhcGVycy5uaXBzLmNjL3BhcGVyLzUzNDctaG93LXRyYW5zZmVyYWJsZS1hcmUtZmVhdHVyZXMtaW4tZGVlcC1uZXVyYWwtbmV0d29ya3MucGRm">http://papers.nips.cc/paper/5347-how-transferable-are-features-in-deep-neural-networks.pdf</span></p></blockquote><p>本文通过实验，量化了深度神经网络每层神经元的通用性与特殊性，并对结果进行了展示。网络第一层的特征并非特定于某一数据集或者某一任务，而是通用的特征，它们适用于许多数据集和普遍的任务。在较深的模型层，特征会从通用的特征逐渐转换为更专业的特征（和任务、数据集紧密相关的特征）。</p></li><li><p>CNN features off-the-Shelf: An astounding baseline for recognition (2014), A. Razavian et al.</p><blockquote><p><span class="exturl" data-url="aHR0cDovL3d3dy5jdi1mb3VuZGF0aW9uLm9yZy8vb3BlbmFjY2Vzcy9jb250ZW50X2N2cHJfd29ya3Nob3BzXzIwMTQvVzE1L3BhcGVycy9SYXphdmlhbl9DTk5fRmVhdHVyZXNfT2ZmLXRoZS1TaGVsZl8yMDE0X0NWUFJfcGFwZXIucGRm">http://www.cv-foundation.org//openaccess/content_cvpr_workshops_2014/W15/papers/Razavian_CNN_Features_Off-the-Shelf_2014_CVPR_paper.pdf</span></p></blockquote><p>本文考虑了一种问题，假设有一个现成的，针对某个具体问题 A 训练好的 CNN，仅仅使用它的前几层来提取图像信息，再配合使用一些经典分类器（SVM 等），是否可以在其他的问题 B，C 上也得到比较好的结果？</p></li><li><p>Learning and transferring mid-Level image representations using convolutional neural networks (2014), M. Oquab et al.</p><blockquote><p><span class="exturl" data-url="aHR0cHM6Ly93d3cuY3YtZm91bmRhdGlvbi5vcmcvb3BlbmFjY2Vzcy9jb250ZW50X2N2cHJfMjAxNC9wYXBlcnMvT3F1YWJfTGVhcm5pbmdfYW5kX1RyYW5zZmVycmluZ18yMDE0X0NWUFJfcGFwZXIucGRm">https://www.cv-foundation.org/openaccess/content_cvpr_2014/papers/Oquab_Learning_and_Transferring_2014_CVPR_paper.pdf</span></p></blockquote><p>CNN 的学习需要建立数以百万计的参数，并且需要大量已经标注好的图像。这种特性目前阻止了 CNN 在有限训练集问题上的应用。本文展示了在大规模标记的数据上、用 CNN 学习出的图像表示，是如何有效地被迁移到其他视觉识别的任务中的。</p></li><li><p>Visualizing and understanding convolutional networks (2014), M. Zeiler and R. Fergus</p><blockquote><p><span class="exturl" data-url="aHR0cDovL2FyeGl2Lm9yZy9wZGYvMTMxMS4yOTAx">http://arxiv.org/pdf/1311.2901</span></p></blockquote><p>这篇论文的目的，就是通过特征可视化，查看精度变化，从而知道 CNN 学习到的特征如何。这篇论文阐述了 CNN 的每一层到底学习到了什么特征，然后作者通过可视化进行调整网络。</p></li><li><p>Decaf: A deep convolutional activation feature for generic visual recognition (2014), J. Donahue et al.</p><blockquote><p><span class="exturl" data-url="aHR0cDovL2FyeGl2Lm9yZy9wZGYvMTMxMC4xNTMx">http://arxiv.org/pdf/1310.1531</span></p></blockquote><p>这篇论文验证了卷积特征在各种场合上的效果，算是 transfer learning 和一些验证的论文。而且，DeCAF 可以算是著名的框架 Caffe 的前身。</p></li></ol><h3 id="优化-技巧方法"><a class="anchor" href="#优化-技巧方法">#</a> 优化、技巧方法</h3><ol start="8"><li><p>Training very deep networks (2015), R. Srivastava et al.</p><blockquote><p><span class="exturl" data-url="aHR0cDovL3BhcGVycy5uaXBzLmNjL3BhcGVyLzU4NTAtdHJhaW5pbmctdmVyeS1kZWVwLW5ldHdvcmtzLnBkZg==">http://papers.nips.cc/paper/5850-training-very-deep-networks.pdf</span></p></blockquote><p>作者提出了一种全新的高速网络结构 (Highway Networks)，用于优化深度神经网络由于梯度爆炸和梯度消失而导致的训练困难的问题。而且，ResNet 的思路和这篇文章所提出的想法有很多相似之处。（小 tips，这篇论文发表于 2015 年 05 月份，ResNet 发表于 2015 年 12 月份）</p></li><li><p>Batch normalization: Accelerating deep network training by reducing internal covariate shift (2015), S. Loffe and C. Szegedy</p><blockquote><p><span class="exturl" data-url="aHR0cDovL2FyeGl2Lm9yZy9wZGYvMTUwMi4wMzE2Nw==">http://arxiv.org/pdf/1502.03167</span></p></blockquote><p>这篇文章引入了 BN 层，并介绍了引入原因。引入 BN 后，我们可以不用太在意参数的初始化，同时使用更大的学习率，而且也会有正则化的效果，在一些情况下可以不用再使用 Dropout。</p></li><li><p>Delving deep into rectifiers: Surpassing human-level performance on imagenet classification (2015), K. He et al.</p><blockquote><p><span class="exturl" data-url="aHR0cDovL3d3dy5jdi1mb3VuZGF0aW9uLm9yZy9vcGVuYWNjZXNzL2NvbnRlbnRfaWNjdl8yMDE1L3BhcGVycy9IZV9EZWx2aW5nX0RlZXBfaW50b19JQ0NWXzIwMTVfcGFwZXIucGRm">http://www.cv-foundation.org/openaccess/content_iccv_2015/papers/He_Delving_Deep_into_ICCV_2015_paper.pdf</span></p></blockquote><p>这篇论文是来自 MSRA 的何恺明的论文，论文首次公开宣布图像的识别率超越人类水平。</p></li><li><p>Dropout: A simple way to prevent neural networks from overfitting (2014), N. Srivastava et al.</p><blockquote><p><span class="exturl" data-url="aHR0cDovL2ptbHIub3JnL3BhcGVycy92b2x1bWUxNS9zcml2YXN0YXZhMTRhL3NyaXZhc3RhdmExNGEucGRm">http://jmlr.org/papers/volume15/srivastava14a/srivastava14a.pdf</span></p></blockquote><p>大牛集结的论文，Hinton、Bengio 都有参与。这篇文章对 dropout 进行了研究，结果表明，在视觉、语音识别、文档分类和计算生物学等方面，dropout 都能提高神经网络在有监督学习任务中的性能，在许多基准数据集上都获得了最新的结果。</p></li><li><p>Adam: A method for stochastic optimization (2014), D. Kingma and J. Ba</p><blockquote><p><span class="exturl" data-url="aHR0cDovL2FyeGl2Lm9yZy9wZGYvMTQxMi42OTgw">http://arxiv.org/pdf/1412.6980</span></p></blockquote><p>本文展示了如何将优化算法的设计转换为一个学习问题，使算法能够自动地在感兴趣的问题中利用结构。文中的学习算法由 LSTMs 实现。</p></li><li><p>Improving neural networks by preventing co-adaptation of feature detectors (2012), G. Hinton et al.</p><blockquote><p><span class="exturl" data-url="aHR0cDovL2FyeGl2Lm9yZy9wZGYvMTIwNy4wNTgwLnBkZg==">http://arxiv.org/pdf/1207.0580.pdf</span></p></blockquote><p>Hinton 的论文，文章对过拟合问题进行了研究。训练网络时，随机忽略一半的 feature detectors 能够防止因训练集太小带来的过拟合问题。这能够防止一些 detectors 联合在一起才起作用的情况，每个神经元预测一个特征有利于提高准确率，这种 dropout 的方法能提高很多 benchmark 的成绩。</p></li><li><p>Random search for hyper-parameter optimization (2012) J. Bergstra and Y. Bengio</p><blockquote><p><span class="exturl" data-url="aHR0cDovL3d3dy5qbWxyLm9yZy9wYXBlcnMvdm9sdW1lMTMvYmVyZ3N0cmExMmEvYmVyZ3N0cmExMmE=">http://www.jmlr.org/papers/volume13/bergstra12a/bergstra12a</span></p></blockquote><p>Bengio 的论文，关于超参数优化的方法。论文指出，Random Search 比 Gird Search 更有效。实际操作的时候，一般也是先用 Gird Search 的方法，得到所有候选参数，然后每次从中随机选择进行训练。</p></li></ol><h3 id="无监督学习-生成模型"><a class="anchor" href="#无监督学习-生成模型">#</a> 无监督学习、生成模型</h3><ol start="15"><li><p>Pixel recurrent neural networks (2016), A. Oord et al.</p><blockquote><p><span class="exturl" data-url="aHR0cDovL2FyeGl2Lm9yZy9wZGYvMTYwMS4wNjc1OXYyLnBkZg==">http://arxiv.org/pdf/1601.06759v2.pdf</span></p></blockquote><p>本文提出了一个深度神经网络，它根据顺序沿着两个空间维度来预测图片中的像素。这种模型离散了原始像素值的可能性，同时编码保证了整个图片的完整性。对自然图片的分布进行建模一直以来都是无监督学习中的里程碑式的难题。这要求图片模型易表达、易处理、可拓展。</p></li><li><p>Improved techniques for training GANs (2016), T. Salimans et al.</p><blockquote><p><span class="exturl" data-url="aHR0cDovL3BhcGVycy5uaXBzLmNjL3BhcGVyLzYxMjUtaW1wcm92ZWQtdGVjaG5pcXVlcy1mb3ItdHJhaW5pbmctZ2Fucy5wZGY=">http://papers.nips.cc/paper/6125-improved-techniques-for-training-gans.pdf</span></p></blockquote><p>本文提出了可以用到 GAN 上的一些新的结构特征和训练过程。本文主要应用于半监督学习和生成视觉上真实的图像两个方向。使用这种方法，可以在 MNIST，CIFAR10，SVHN 上达到很好的半监督效果。</p></li><li><p>Unsupervised representation learning with deep convolutional generative adversarial networks (2015), A. Radford et al.</p><blockquote><p><span class="exturl" data-url="aHR0cHM6Ly9hcnhpdi5vcmcvcGRmLzE1MTEuMDY0MzR2Mg==">https://arxiv.org/pdf/1511.06434v2</span></p></blockquote><p>这篇论文旨在帮助缩小监督学习和非监督学习成功运用于 CNN 上的差距。论文介绍了 CNN 的一个类，称为深度卷积生成对抗网络（DCGANs），这个网络有着明确的结构约束，并且表明他们对非监督学习有着强烈的可信度。</p></li><li><p>DRAW: A recurrent neural network for image generation (2015), K. Gregor et al.</p><blockquote><p><span class="exturl" data-url="aHR0cDovL2FyeGl2Lm9yZy9wZGYvMTUwMi4wNDYyMw==">http://arxiv.org/pdf/1502.04623</span></p></blockquote><p>本文介绍了深度递归书写器（DRAW）神经网络用于图像生成。DRAW 网络是一种模仿人眼空间注意力机制的、带有视觉偏好性的可变自动编码框架，其主要功能是用于复杂图像的迭代构造。</p></li><li><p>Generative adversarial nets (2014), I. Goodfellow et al.</p><blockquote><p><span class="exturl" data-url="aHR0cDovL3BhcGVycy5uaXBzLmNjL3BhcGVyLzU0MjMtZ2VuZXJhdGl2ZS1hZHZlcnNhcmlhbC1uZXRzLnBkZg==">http://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf</span></p></blockquote><p>GANs 来了。论文提出了一个通过对抗过程估计生成模型的新框架，在新框架中同时训练两个模型：一个用来捕获数据分布的生成模型 G，和一个用来估计样本来自训练数据而不是 G 的概率的判别模型 D，G 的训练过程是最大化 D 产生错误的概率。在训练或生成样本期间不需要任何马尔科夫链或展开的近似推理网络。</p></li><li><p>Auto-encoding variational Bayes (2013), D. Kingma and M. Welling</p><blockquote><p><span class="exturl" data-url="aHR0cDovL2FyeGl2Lm9yZy9wZGYvMTMxMi42MTE0">http://arxiv.org/pdf/1312.6114</span></p></blockquote><p>AEV 与 GAN 是现在生成网络中的两个趋势。文中引入了随机变分推理和学习算法，扩展到大数据集，并且可以在一些温和的差异性条件下、甚至某些棘手的情况下工作。论文表明，变分下界的重新参数化产生了可以使用标准随机梯度法直接优化的下限估计器。</p></li><li><p>Building high-level features using large scale unsupervised learning (2013), Q. Le et al.</p><blockquote><p><span class="exturl" data-url="aHR0cDovL2FyeGl2Lm9yZy9wZGYvMTExMi42MjA5">http://arxiv.org/pdf/1112.6209</span></p></blockquote><p>GoogleBrain 中特征学习的原理，通过使用未标记的图像学习人脸、猫脸 high-level 特征，得到检测器。文章使用大数据构建了一个 9 层的局部连接稀疏自编码网络，使用模型并行化和异步 SGD 在 1000 个机器（16000 核）上训练了 3 天，结果显示，可以在未标记图像是否有人脸的情况下训练出一个人脸检测器。</p></li></ol><p>由于文章比较多，此处只介绍前 20 篇论文，除此之外，还有卷积神经网络模型、目标检测、视频图像处理、NLP 算法、RNN 模型、强化学习和机器人领域等近年来最经典的论文。</p><p>对机器学习感兴趣的朋友们，可以点击下方链接，选择自己感兴趣的领域进行学习。</p><h2 id="传送门"><a class="anchor" href="#传送门">#</a> 传送门</h2><p><span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL3RlcnJ5dW0vYXdlc29tZS1kZWVwLWxlYXJuaW5nLXBhcGVycyN1bmRlcnN0YW5kaW5nLS1nZW5lcmFsaXphdGlvbi0tdHJhbnNmZXI=">机器学习 TOP 100 论文</span></p><h2 id="文章来源"><a class="anchor" href="#文章来源">#</a> 文章来源</h2><p><span class="exturl" data-url="aHR0cHM6Ly9tcC53ZWl4aW4ucXEuY29tL3MvWjZqQms5cFhpWXhpRHJBNXhySmxNdw==">机器学习必读 TOP 100 论文清单：高引用、分类全、覆盖面广丨 GitHub 21.4k 星</span></p><div class="tags"><a href="/tags/%E8%B5%84%E6%BA%90/" rel="tag"><i class="ic i-tag"></i> 资源</a></div></div><footer><div class="meta"><span class="item"><span class="icon"><i class="ic i-calendar-check"></i> </span><span class="text">更新于</span> <time title="修改时间：2022-03-12 11:19:28" itemprop="dateModified" datetime="2022-03-12T11:19:28+08:00">2022-03-12</time> </span><span id="resources/20200718/" class="item leancloud_visitors" data-flag-title="机器学习必读TOP100论文清单" title="阅读次数"><span class="icon"><i class="ic i-eye"></i> </span><span class="text">阅读次数</span> <span class="leancloud-visitors-count"></span> <span class="text">次</span></span></div><div class="reward"><button><i class="ic i-heartbeat"></i> 赞赏</button><p>请我喝[茶]~(￣▽￣)~*</p><div id="qr"><div><img data-src="/images/wechatpay.png" alt="宇凌喵 微信支付"><p>微信支付</p></div><div><img data-src="/images/alipay.png" alt="宇凌喵 支付宝"><p>支付宝</p></div></div></div><div id="copyright"><ul><li class="author"><strong>本文作者： </strong>宇凌喵 <i class="ic i-at"><em>@</em></i>学无止境</li><li class="link"><strong>本文链接：</strong> <a href="https://blog.aayu.today/resources/20200718/" title="机器学习必读TOP100论文清单">https://blog.aayu.today/resources/20200718/</a></li><li class="license"><strong>版权声明： </strong>本站所有文章除特别声明外，均采用 <span class="exturl" data-url="aHR0cHM6Ly9jcmVhdGl2ZWNvbW1vbnMub3JnL2xpY2Vuc2VzL2J5LW5jLXNhLzQuMC9kZWVkLnpo"><i class="ic i-creative-commons"><em>(CC)</em></i>BY-NC-SA</span> 许可协议。转载请注明出处！</li></ul></div></footer></article></div><div class="post-nav"><div class="item left"><a href="/english/ielts/20200717/" itemprop="url" rel="prev" data-background-image="https:&#x2F;&#x2F;tva4.sinaimg.cn&#x2F;mw690&#x2F;6833939bly1giciuv0socj20zk0m8qes.jpg" title="雅思写作-常用谚语（二）"><span class="type">上一篇</span> <span class="category"><i class="ic i-flag"></i> 雅思备战</span><h3>雅思写作-常用谚语（二）</h3></a></div><div class="item right"><a href="/leisure/mood/20200719/" itemprop="url" rel="next" data-background-image="https:&#x2F;&#x2F;tva4.sinaimg.cn&#x2F;mw690&#x2F;6833939bly1giciukx8a7j20zk0m8aio.jpg" title="心情-创建自己的论文学习笔记库"><span class="type">下一篇</span> <span class="category"><i class="ic i-flag"></i> 心情</span><h3>心情-创建自己的论文学习笔记库</h3></a></div></div><div class="wrap" id="comments"></div></div><div id="sidebar"><div class="inner"><div class="panels"><div class="inner"><div class="contents panel pjax" data-title="文章目录"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%89%8D%E8%A8%80"><span class="toc-number">1.</span> <span class="toc-text">前言</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%B8%85%E5%8D%95%E5%88%97%E8%A1%A8"><span class="toc-number">2.</span> <span class="toc-text">清单列表</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%90%86%E8%A7%A3-%E6%B3%9B%E5%8C%96-%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0"><span class="toc-number">2.1.</span> <span class="toc-text">理解、泛化、迁移学习</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BC%98%E5%8C%96-%E6%8A%80%E5%B7%A7%E6%96%B9%E6%B3%95"><span class="toc-number">2.2.</span> <span class="toc-text">优化、技巧方法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0-%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B"><span class="toc-number">2.3.</span> <span class="toc-text">无监督学习、生成模型</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BC%A0%E9%80%81%E9%97%A8"><span class="toc-number">3.</span> <span class="toc-text">传送门</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%96%87%E7%AB%A0%E6%9D%A5%E6%BA%90"><span class="toc-number">4.</span> <span class="toc-text">文章来源</span></a></li></ol></div><div class="related panel pjax" data-title="系列文章"><ul><li><a href="/resources/20200711/" rel="bookmark" title="GitHub上10个好看的可视化面板">GitHub上10个好看的可视化面板</a></li><li><a href="/resources/20200712/" rel="bookmark" title="吴恩达家免费NLP课程上线">吴恩达家免费NLP课程上线</a></li><li class="active"><a href="/resources/20200718/" rel="bookmark" title="机器学习必读TOP100论文清单">机器学习必读TOP100论文清单</a></li><li><a href="/resources/20210723/" rel="bookmark" title="空间统计系列科普文章">空间统计系列科普文章</a></li><li><a href="/resources/20210816/" rel="bookmark" title="超好用的C++库推荐">超好用的C++库推荐</a></li><li><a href="/resources/20210923/" rel="bookmark" title="机器学习实战(高清中文版PDF+高清英文版PDF+源代码)免密码版本">机器学习实战(高清中文版PDF+高清英文版PDF+源代码)免密码版本</a></li></ul></div><div class="overview panel" data-title="站点概览"><div class="author" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="image" itemprop="image" alt="宇凌喵" data-src="/images/avatar.jpg"><p class="name" itemprop="name">宇凌喵</p><div class="description" itemprop="description">真理和热爱是吾永生的追求</div></div><nav class="state"><div class="item posts"><a href="/archives/"><span class="count">279</span> <span class="name">文章</span></a></div><div class="item categories"><a href="/categories/"><span class="count">77</span> <span class="name">分类</span></a></div><div class="item tags"><a href="/tags/"><span class="count">88</span> <span class="name">标签</span></a></div></nav><div class="social"><span class="exturl item github" data-url="aHR0cHM6Ly9naXRodWIuY29tL3lsc2lzbG92ZQ==" title="https:&#x2F;&#x2F;github.com&#x2F;ylsislove"><i class="ic i-github"></i></span> <span class="exturl item weibo" data-url="aHR0cHM6Ly93ZWliby5jb20veW91cm5hbWU=" title="https:&#x2F;&#x2F;weibo.com&#x2F;yourname"><i class="ic i-weibo"></i></span> <span class="exturl item email" data-url="bWFpbHRvOjkxNjQ5MTAxM0BxcS5jb20=" title="mailto:916491013@qq.com"><i class="ic i-envelope"></i></span></div><ul class="menu"><li class="item"><a href="/" rel="section"><i class="ic i-home"></i>首页</a></li><li class="item"><a href="/about/" rel="section"><i class="ic i-user"></i>关于</a></li><li class="item dropdown"><a href="javascript:void(0);"><i class="ic i-feather"></i>文章</a><ul class="submenu"><li class="item"><a href="/archives/" rel="section"><i class="ic i-list-alt"></i>归档</a></li><li class="item"><a href="/categories/" rel="section"><i class="ic i-th"></i>分类</a></li><li class="item"><a href="/tags/" rel="section"><i class="ic i-tags"></i>标签</a></li></ul></li><li class="item dropdown"><a href="javascript:void(0);"><i class="ic i-magic"></i>链环</a><ul class="submenu"><li class="item"><a href="/friends/" rel="section"><i class="ic i-heart"></i>友達</a></li><li class="item"><a href="/webstack/" rel="section"><i class="ic i-star"></i>网址</a></li></ul></li><li class="item"><span class="exturl" data-url="aHR0cHM6Ly9mb3JldmVyYmxvZy5jbi9nby5odG1s"><i class="ic i-paper-plane"></i>虫洞</span></li></ul></div></div></div><ul id="quick"><li class="prev pjax"><a href="/english/ielts/20200717/" rel="prev" title="上一篇"><i class="ic i-chevron-left"></i></a></li><li class="up"><i class="ic i-arrow-up"></i></li><li class="down"><i class="ic i-arrow-down"></i></li><li class="next pjax"><a href="/leisure/mood/20200719/" rel="next" title="下一篇"><i class="ic i-chevron-right"></i></a></li><li class="percent"></li></ul></div></div><div class="dimmer"></div></div></main><footer id="footer"><div class="inner"><div class="widgets"><div class="rpost pjax"><h2>随机文章</h2><ul><li class="item"><div class="breadcrumb"><a href="/categories/artificial-intelligence/" title="分类于 人工智能-迎接末日的审判吧">人工智能-迎接末日的审判吧</a> <i class="ic i-angle-right"></i> <a href="/categories/artificial-intelligence/opencv/" title="分类于 OpenCV">OpenCV</a> <i class="ic i-angle-right"></i> <a href="/categories/artificial-intelligence/opencv/getting-started/" title="分类于 入门">入门</a></div><span><a href="/artificial-intelligence/opencv/getting-started/20201107/" title="OpenCV4（1）-读取和显示图像（C++，Python，JS）">OpenCV4（1）-读取和显示图像（C++，Python，JS）</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/back-end/" title="分类于 后端系列">后端系列</a> <i class="ic i-angle-right"></i> <a href="/categories/back-end/nodejs/" title="分类于 NodeJS">NodeJS</a></div><span><a href="/back-end/nodejs/20200928/" title="NodeJS-npm安装命令详解">NodeJS-npm安装命令详解</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/artificial-intelligence/" title="分类于 人工智能-迎接末日的审判吧">人工智能-迎接末日的审判吧</a> <i class="ic i-angle-right"></i> <a href="/categories/artificial-intelligence/yolov5/" title="分类于 YOLOv5">YOLOv5</a></div><span><a href="/artificial-intelligence/yolov5/20210912-2/" title="YOLOv5-模型部署">YOLOv5-模型部署</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/artificial-intelligence/" title="分类于 人工智能-迎接末日的审判吧">人工智能-迎接末日的审判吧</a> <i class="ic i-angle-right"></i> <a href="/categories/artificial-intelligence/opencv/" title="分类于 OpenCV">OpenCV</a> <i class="ic i-angle-right"></i> <a href="/categories/artificial-intelligence/opencv/getting-started/" title="分类于 入门">入门</a></div><span><a href="/artificial-intelligence/opencv/getting-started/20201126/" title="OpenCV4（20）-图像直方图反向投影（C++，Python，JS）">OpenCV4（20）-图像直方图反向投影（C++，Python，JS）</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/front-end/" title="分类于 前端系列">前端系列</a> <i class="ic i-angle-right"></i> <a href="/categories/front-end/css/" title="分类于 CSS">CSS</a></div><span><a href="/front-end/css/20210105/" title="CSS-赛博朋克故障风格按钮">CSS-赛博朋克故障风格按钮</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/artificial-intelligence/" title="分类于 人工智能-迎接末日的审判吧">人工智能-迎接末日的审判吧</a> <i class="ic i-angle-right"></i> <a href="/categories/artificial-intelligence/opencv/" title="分类于 OpenCV">OpenCV</a> <i class="ic i-angle-right"></i> <a href="/categories/artificial-intelligence/opencv/getting-started/" title="分类于 入门">入门</a></div><span><a href="/artificial-intelligence/opencv/getting-started/20201122/" title="OpenCV4（16）-图像ROI与ROI操作（C++，Python，JS）">OpenCV4（16）-图像ROI与ROI操作（C++，Python，JS）</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/artificial-intelligence/" title="分类于 人工智能-迎接末日的审判吧">人工智能-迎接末日的审判吧</a> <i class="ic i-angle-right"></i> <a href="/categories/artificial-intelligence/opencv/" title="分类于 OpenCV">OpenCV</a> <i class="ic i-angle-right"></i> <a href="/categories/artificial-intelligence/opencv/getting-started/" title="分类于 入门">入门</a></div><span><a href="/artificial-intelligence/opencv/getting-started/20201118/" title="OpenCV4（12）-视频读写（C++，Python，JS）">OpenCV4（12）-视频读写（C++，Python，JS）</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/feature/" title="分类于 HoloLens2开发笔记">HoloLens2开发笔记</a> <i class="ic i-angle-right"></i> <a href="/categories/feature/unity/" title="分类于 Unity3D">Unity3D</a></div><span><a href="/feature/unity/20210509/" title="HoloLens2-使用UWP原生MediaCapture解决图像捕获与WebRTC视频流冲突问题">HoloLens2-使用UWP原生MediaCapture解决图像捕获与WebRTC视频流冲突问题</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/computer-graphics/" title="分类于 计算机图形学">计算机图形学</a> <i class="ic i-angle-right"></i> <a href="/categories/computer-graphics/svg/" title="分类于 SVG">SVG</a></div><span><a href="/computer-graphics/svg/20201015/" title="SVG入门-如何手写SVG">SVG入门-如何手写SVG</a></span></li><li class="item"><div class="breadcrumb"><a href="/categories/skill/" title="分类于 不看会后悔的实用技巧分享">不看会后悔的实用技巧分享</a> <i class="ic i-angle-right"></i> <a href="/categories/skill/tools/" title="分类于 工具篇">工具篇</a></div><span><a href="/skill/tools/20200724/" title="用Docker科学上网">用Docker科学上网</a></span></li></ul></div><div><h2>最新评论</h2><ul class="leancloud-recent-comment"></ul></div></div><div class="status"><div class="copyright">&copy; 2020 – <span itemprop="copyrightYear">2022</span> <span class="with-love"><i class="ic i-sakura rotate"></i> </span><span class="author" itemprop="copyrightHolder">宇凌喵 @ Aayu Yain</span></div><div class="count"><span class="post-meta-item-icon"><i class="ic i-chart-area"></i> </span><span title="站点总字数">552k 字</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="ic i-coffee"></i> </span><span title="站点阅读时长">8:22</span></div><div class="powered-by">基于 <span class="exturl" data-url="aHR0cHM6Ly9oZXhvLmlv">Hexo</span> & Theme.<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2FtZWhpbWUvaGV4by10aGVtZS1zaG9rYQ==">Shoka</span></div></div></div></footer></div><script data-config type="text/javascript">var LOCAL={path:"resources/20200718/",favicon:{show:"（●´3｀●）やれやれだぜ",hide:"(´Д｀)大変だ！"},search:{placeholder:"文章搜索",empty:"关于 「 ${query} 」，什么也没搜到",stats:"${time} ms 内找到 ${hits} 条结果"},valine:!0,fancybox:!0,copyright:'复制成功，转载请遵守 <i class="ic i-creative-commons"></i>BY-NC-SA 协议。',ignores:[function(e){return e.includes("#")},function(e){return new RegExp(LOCAL.path+"$").test(e)}]}</script><script src="https://cdn.polyfill.io/v2/polyfill.js"></script><script src="//cdn.jsdelivr.net/combine/npm/pace-js@1.0.2/pace.min.js,npm/pjax@0.2.8/pjax.min.js,npm/whatwg-fetch@3.4.0/dist/fetch.umd.min.js,npm/animejs@3.2.0/lib/anime.min.js,npm/algoliasearch@4/dist/algoliasearch-lite.umd.js,npm/instantsearch.js@4/dist/instantsearch.production.min.js,npm/lozad@1/dist/lozad.min.js,npm/quicklink@2/dist/quicklink.umd.js"></script><script src="/js/app.js?v=0.2.5"></script></body></html><!-- rebuild by hrmmi -->